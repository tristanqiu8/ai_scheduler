#!/usr/bin/env python3
"""
ä¿®å¤å†²çªçš„å¢å¼ºä¼˜åŒ–å™¨
è§£å†³åˆ†æ®µä»»åŠ¡å¯¼è‡´çš„èµ„æºå†²çªé—®é¢˜
"""

import sys
import os
import copy
from typing import List, Dict, Tuple, Optional, Set
from collections import defaultdict

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.enums import ResourceType, TaskPriority, RuntimeType, SegmentationStrategy
from core.models import TaskScheduleInfo
from core.scheduler import MultiResourceScheduler
from core.task import NNTask
from core.modular_scheduler_fixes import apply_basic_fixes
from core.minimal_fifo_fix_corrected import apply_minimal_fifo_fix
from core.strict_resource_conflict_fix import apply_strict_resource_conflict_fix
from core.fixed_validation_and_metrics import validate_schedule_correctly
from core.debug_compactor import DebugCompactor
from scenario.real_task import create_real_tasks
from viz.elegant_visualization import ElegantSchedulerVisualizer
import matplotlib.pyplot as plt


class ConflictFreeOptimizer:
    """ä¿®å¤å†²çªçš„ä¼˜åŒ–å™¨"""
    
    def __init__(self, scheduler: MultiResourceScheduler, time_window: float = 200.0):
        self.scheduler = scheduler
        self.time_window = time_window
        self.resource_busy_times = defaultdict(list)  # resource_id -> [(start, end, task_id)]
        
    def optimize_complete(self, max_iterations: int = 3) -> List[TaskScheduleInfo]:
        """å®Œæ•´ä¼˜åŒ–æµç¨‹ï¼ˆä¿®å¤å†²çªç‰ˆï¼‰"""
        print("\nğŸš€ å¼€å§‹æ— å†²çªçš„å®Œæ•´è°ƒåº¦ä¼˜åŒ–æµç¨‹")
        print("=" * 60)
        
        # é¢„å¤„ç†ï¼šå¼ºåˆ¶T2å’ŒT3ä½¿ç”¨æœ€å¤§åˆ†æ®µ
        self._force_segmentation_for_long_tasks()
        
        # ç¬¬ä¸€æ­¥ï¼šè´ªå¿ƒè°ƒåº¦
        print("\n[æ­¥éª¤1] æ‰§è¡Œè´ªå¿ƒè°ƒåº¦...")
        self.scheduler.schedule_history.clear()
        current_schedule = self.scheduler.priority_aware_schedule_with_segmentation(self.time_window)
        self._print_fps_status(current_schedule, "è´ªå¿ƒè°ƒåº¦")
        self._validate_and_print_conflicts(current_schedule, "è´ªå¿ƒè°ƒåº¦")
        
        # è¿­ä»£ä¼˜åŒ–
        for iteration in range(max_iterations):
            print(f"\n{'='*60}")
            print(f"ç¬¬ {iteration + 1} è½®ä¼˜åŒ–")
            print(f"{'='*60}")
            
            # æ­¥éª¤2ï¼šå¢å¼ºçš„æ’ç©ºéš™ï¼ˆå¸¦å†²çªæ£€æŸ¥ï¼‰
            print(f"\n[æ­¥éª¤2-{iteration+1}] å¢å¼ºçš„æ’ç©ºéš™...")
            current_schedule = self._enhanced_fill_gaps_safe(current_schedule)
            self._print_fps_status(current_schedule, f"ç¬¬{iteration+1}è½®æ’ç©ºéš™")
            self._validate_and_print_conflicts(current_schedule, f"ç¬¬{iteration+1}è½®æ’ç©ºéš™")
            
            # æ­¥éª¤3ï¼šç´§å‡‘åŒ–
            print(f"\n[æ­¥éª¤3-{iteration+1}] æ‰§è¡Œç´§å‡‘åŒ–...")
            current_schedule, idle_time = self._compact_schedule(current_schedule)
            print(f"  âœ“ ç´§å‡‘åŒ–å®Œæˆï¼Œæœ«å°¾ç©ºé—²æ—¶é—´: {idle_time:.1f}ms ({idle_time/self.time_window*100:.1f}%)")
            self._validate_and_print_conflicts(current_schedule, f"ç¬¬{iteration+1}è½®ç´§å‡‘åŒ–")
            
            # æ­¥éª¤4ï¼šæ»¡è¶³å¸§ç‡ï¼ˆè´ªå¿ƒè¡¥å……ï¼‰
            print(f"\n[æ­¥éª¤4-{iteration+1}] è´ªå¿ƒè¡¥å……æœªè¾¾æ ‡ä»»åŠ¡...")
            current_schedule = self._greedy_fill_fps_safe(current_schedule)
            self._print_fps_status(current_schedule, f"ç¬¬{iteration+1}è½®è´ªå¿ƒè¡¥å……")
            self._validate_and_print_conflicts(current_schedule, f"ç¬¬{iteration+1}è½®è´ªå¿ƒè¡¥å……")
            
            # æ­¥éª¤5ï¼šæœ€ç»ˆç´§å‡‘åŒ–
            print(f"\n[æ­¥éª¤5-{iteration+1}] æœ€ç»ˆç´§å‡‘åŒ–...")
            current_schedule, idle_time = self._compact_schedule(current_schedule)
            print(f"  âœ“ æœ€ç»ˆç©ºé—²æ—¶é—´: {idle_time:.1f}ms ({idle_time/self.time_window*100:.1f}%)")
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä»»åŠ¡éƒ½è¾¾æ ‡
            if self._check_all_fps_satisfied(current_schedule):
                print(f"\nâœ… ç¬¬{iteration+1}è½®ä¼˜åŒ–åæ‰€æœ‰ä»»åŠ¡FPSè¾¾æ ‡ï¼")
                break
        
        return current_schedule
    
    def _validate_and_print_conflicts(self, schedule: List[TaskScheduleInfo], stage_name: str):
        """éªŒè¯å¹¶æ‰“å°å†²çªä¿¡æ¯"""
        # ä¸´æ—¶æ›´æ–°è°ƒåº¦å™¨å†å²ä»¥ä½¿ç”¨éªŒè¯å‡½æ•°
        self.scheduler.schedule_history = schedule
        is_valid, conflicts = validate_schedule_correctly(self.scheduler)
        
        if not is_valid:
            print(f"\n  âš ï¸ {stage_name}åå‘ç°{len(conflicts)}ä¸ªå†²çª:")
            for i, conflict in enumerate(conflicts[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"    - {conflict}")
            if len(conflicts) > 3:
                print(f"    ... è¿˜æœ‰{len(conflicts)-3}ä¸ªå†²çª")
        else:
            print(f"  âœ… {stage_name}åæ— å†²çª")
    
    def _force_segmentation_for_long_tasks(self):
        """å¼ºåˆ¶T2å’ŒT3ä½¿ç”¨æœ€å¤§åˆ†æ®µ"""
        print("\n[é¢„å¤„ç†] å¼ºåˆ¶é•¿ä»»åŠ¡åˆ†æ®µ...")
        
        for task_id in ['T2', 'T3']:
            task = self.scheduler.tasks.get(task_id)
            if task:
                # ç¡®ä¿ä½¿ç”¨CUSTOM_SEGMENTATIONç­–ç•¥
                task.segmentation_strategy = SegmentationStrategy.CUSTOM_SEGMENTATION
                
                # é€‰æ‹©æœ€å¤§åˆ†æ®µé…ç½®
                if hasattr(task, 'preset_cut_configurations'):
                    for seg_id, configs in task.preset_cut_configurations.items():
                        if configs:
                            # é€‰æ‹©cutç‚¹æœ€å¤šçš„é…ç½®ï¼ˆé€šå¸¸æ˜¯æœ€åä¸€ä¸ªï¼‰
                            max_cuts_idx = len(configs) - 1
                            task.select_cut_configuration(seg_id, max_cuts_idx)
                            print(f"  âœ“ {task_id}: é€‰æ‹©é…ç½®{max_cuts_idx}ï¼ˆ{len(configs[max_cuts_idx])}ä¸ªåˆ‡åˆ†ç‚¹ï¼‰")
                
                # ç¡®ä¿åˆ†æ®µè¢«åº”ç”¨
                for segment in task.segments:
                    if segment.segment_id == "main" and segment.cut_points:
                        # è·å–æ‰€æœ‰å¯ç”¨çš„cutç‚¹
                        all_cuts = [cp.op_id for cp in segment.cut_points]
                        segment.apply_segmentation(all_cuts)
                        print(f"    å·²åº”ç”¨{len(segment.sub_segments)}ä¸ªå­æ®µ")
    
    def _enhanced_fill_gaps_safe(self, schedule: List[TaskScheduleInfo]) -> List[TaskScheduleInfo]:
        """å®‰å…¨çš„å¢å¼ºç©ºéš™å¡«å……ï¼ˆé¿å…å†²çªï¼‰"""
        # é‡å»ºèµ„æºæ—¶é—´çº¿
        self._rebuild_resource_timeline(schedule)
        
        # æ‰¾å‡ºDSPå¿™ç¢Œæ—¶çš„NPUç©ºéš™
        npu_gaps_during_dsp = self._find_npu_gaps_during_dsp_busy(schedule)
        
        if not npu_gaps_during_dsp:
            return schedule
        
        print(f"\n  å‘ç°{len(npu_gaps_during_dsp)}ä¸ªDSPå¿™ç¢Œæ—¶çš„NPUç©ºéš™")
        
        new_schedule = copy.deepcopy(schedule)
        
        # ä¼˜å…ˆçº§æ’åºçš„çº¯NPUä»»åŠ¡
        pure_npu_tasks = [
            ('T6', 0.778),  # HIGHä¼˜å…ˆçº§ï¼Œæœ€çŸ­
            ('T4', 0.364),  # NORMALä¼˜å…ˆçº§ï¼Œå¾ˆçŸ­
            ('T5', 0.755),  # NORMALä¼˜å…ˆçº§ï¼ŒçŸ­
            ('T7', 3.096),  # NORMALä¼˜å…ˆçº§ï¼Œè¾ƒé•¿
        ]
        
        # ä¸ºæ¯ä¸ªç©ºéš™å¡«å……ä»»åŠ¡
        for gap_start, gap_end in npu_gaps_during_dsp:
            gap_duration = gap_end - gap_start
            if gap_duration < 0.5:  # å¿½ç•¥å¤ªå°çš„ç©ºéš™
                continue
                
            print(f"\n  å¤„ç†NPUç©ºéš™: {gap_start:.1f}-{gap_end:.1f}ms (æŒç»­{gap_duration:.1f}ms)")
            
            # è·å–æ¯ä¸ªä»»åŠ¡å½“å‰çš„æ‰§è¡Œæ¬¡æ•°
            task_counts = defaultdict(int)
            for event in new_schedule:
                task_counts[event.task_id] += 1
            
            # å°è¯•å¡«å……ä»»åŠ¡
            gap_used = gap_start
            for task_id, duration in pure_npu_tasks:
                if gap_end - gap_used < duration + 0.1:  # ç•™ä¸€ç‚¹ä½™é‡
                    continue
                
                task = self.scheduler.tasks.get(task_id)
                if not task:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´å¤šæ‰§è¡Œ
                expected = int((self.time_window / 1000.0) * task.fps_requirement)
                current = task_counts[task_id]
                
                if current < expected:
                    # æ£€æŸ¥æœ€å°é—´éš”çº¦æŸ
                    existing_times = [e.start_time for e in new_schedule if e.task_id == task_id]
                    valid = True
                    for exist_time in existing_times:
                        if abs(gap_used - exist_time) < task.min_interval_ms:
                            valid = False
                            break
                    
                    if valid:
                        # å†æ¬¡ç¡®è®¤èµ„æºçœŸçš„ç©ºé—²
                        if self._verify_resource_available('NPU_0', gap_used, gap_used + duration):
                            # åˆ›å»ºæ–°äº‹ä»¶
                            resources = {ResourceType.NPU: 'NPU_0'}
                            new_event = self._create_safe_task_event(task, gap_used, resources)
                            new_schedule.append(new_event)
                            # æ›´æ–°èµ„æºæ—¶é—´çº¿
                            self._update_resource_timeline(new_event, task)
                            print(f"    âœ“ åœ¨{gap_used:.1f}mså¤„æ’å…¥{task_id}")
                            
                            gap_used += duration + 0.1
                            task_counts[task_id] += 1
        
        new_schedule.sort(key=lambda x: x.start_time)
        return new_schedule
    
    def _greedy_fill_fps_safe(self, schedule: List[TaskScheduleInfo]) -> List[TaskScheduleInfo]:
        """å®‰å…¨çš„è´ªå¿ƒFPSè¡¥å……"""
        # é‡å»ºèµ„æºæ—¶é—´çº¿
        self._rebuild_resource_timeline(schedule)
        
        # æ‰¾å‡ºæœªè¾¾æ ‡çš„ä»»åŠ¡
        tasks_needing_runs = self._find_tasks_needing_more_runs(schedule)
        
        if not tasks_needing_runs:
            return schedule
        
        new_schedule = copy.deepcopy(schedule)
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºä»»åŠ¡
        for task_id, info in sorted(tasks_needing_runs.items(), 
                                   key=lambda x: x[1]['task'].priority.value):
            task = info['task']
            needed = info['needed']
            
            # è·å–å·²æœ‰æ‰§è¡Œæ—¶é—´
            existing_times = [e.start_time for e in new_schedule if e.task_id == task_id]
            
            added = 0
            for _ in range(needed):
                # è´ªå¿ƒç­–ç•¥ï¼šæ‰¾æœ€æ—©çš„å¯ç”¨æ—¶é—´
                earliest_time = self._find_earliest_safe_time(task, existing_times)
                if earliest_time is not None and earliest_time < self.time_window:
                    resources = self._allocate_resources(task)
                    new_event = self._create_safe_task_event(task, earliest_time, resources)
                    new_schedule.append(new_event)
                    existing_times.append(earliest_time)
                    self._update_resource_timeline(new_event, task)
                    added += 1
                else:
                    break
            
            if added > 0:
                print(f"    {task_id}: è´ªå¿ƒæ·»åŠ äº† {added} æ¬¡æ‰§è¡Œ")
        
        new_schedule.sort(key=lambda x: x.start_time)
        return new_schedule
    
    def _find_earliest_safe_time(self, task: NNTask, existing_times: List[float]) -> Optional[float]:
        """æ‰¾åˆ°ä»»åŠ¡çš„æœ€æ—©å®‰å…¨æ—¶é—´ï¼ˆæ— å†²çªï¼‰"""
        # è®¡ç®—ä»»åŠ¡æ€»æ‰§è¡Œæ—¶é—´
        task_duration = self._get_task_total_duration(task)
        
        # ä»0å¼€å§‹æœç´¢
        test_time = 0.0
        step = 0.5  # æœç´¢æ­¥é•¿
        
        while test_time + task_duration <= self.time_window:
            # æ£€æŸ¥æœ€å°é—´éš”
            valid = True
            for exist_time in existing_times:
                if abs(test_time - exist_time) < task.min_interval_ms:
                    valid = False
                    break
            
            if valid:
                # æ£€æŸ¥æ‰€æœ‰éœ€è¦çš„èµ„æºæ˜¯å¦å¯ç”¨
                if self._check_all_resources_available(task, test_time):
                    return test_time
            
            test_time += step
        
        return None
    
    def _check_all_resources_available(self, task: NNTask, start_time: float) -> bool:
        """æ£€æŸ¥ä»»åŠ¡æ‰€éœ€çš„æ‰€æœ‰èµ„æºæ˜¯å¦å¯ç”¨"""
        current_time = start_time
        
        if task.is_segmented:
            # åˆ†æ®µä»»åŠ¡ï¼šæŒ‰é¡ºåºæ£€æŸ¥æ¯ä¸ªå­æ®µ
            for seg in task.segments:
                if seg.is_segmented and seg.sub_segments:
                    for sub_seg in seg.sub_segments:
                        duration = sub_seg.get_duration(40.0)
                        res_type = sub_seg.resource_type
                        if res_type == ResourceType.NPU:
                            if not self._verify_resource_available('NPU_0', current_time, current_time + duration):
                                return False
                        elif res_type == ResourceType.DSP:
                            if not self._verify_resource_available('DSP_0', current_time, current_time + duration):
                                return False
                        current_time += duration
                else:
                    duration = seg.get_duration(40.0)
                    res_type = seg.resource_type
                    seg_time = start_time + seg.start_time
                    if res_type == ResourceType.NPU:
                        if not self._verify_resource_available('NPU_0', seg_time, seg_time + duration):
                            return False
                    elif res_type == ResourceType.DSP:
                        if not self._verify_resource_available('DSP_0', seg_time, seg_time + duration):
                            return False
        else:
            # éåˆ†æ®µä»»åŠ¡
            for seg in task.segments:
                duration = seg.get_duration(40.0)
                seg_time = start_time + seg.start_time
                res_type = seg.resource_type
                if res_type == ResourceType.NPU:
                    if not self._verify_resource_available('NPU_0', seg_time, seg_time + duration):
                        return False
                elif res_type == ResourceType.DSP:
                    if not self._verify_resource_available('DSP_0', seg_time, seg_time + duration):
                        return False
        
        return True
    
    def _verify_resource_available(self, resource_id: str, start_time: float, end_time: float) -> bool:
        """éªŒè¯èµ„æºåœ¨æŒ‡å®šæ—¶é—´æ®µæ˜¯å¦çœŸçš„å¯ç”¨"""
        for busy_start, busy_end, _ in self.resource_busy_times.get(resource_id, []):
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•é‡å 
            if not (end_time <= busy_start + 0.001 or start_time >= busy_end - 0.001):
                return False
        return True
    
    def _get_task_total_duration(self, task: NNTask) -> float:
        """è·å–ä»»åŠ¡çš„æ€»æŒç»­æ—¶é—´"""
        if task.is_segmented:
            total = 0
            for seg in task.segments:
                if seg.is_segmented and seg.sub_segments:
                    for sub_seg in seg.sub_segments:
                        total += sub_seg.get_duration(40.0)
                else:
                    total += seg.get_duration(40.0)
            return total
        else:
            # å¯¹äºéåˆ†æ®µä»»åŠ¡ï¼Œè¿”å›æœ€æ™šç»“æŸæ—¶é—´
            max_end = 0
            for seg in task.segments:
                seg_end = seg.start_time + seg.get_duration(40.0)
                max_end = max(max_end, seg_end)
            return max_end
    
    def _create_safe_task_event(self, task: NNTask, start_time: float, 
                               resources: Dict[ResourceType, str]) -> TaskScheduleInfo:
        """åˆ›å»ºå®‰å…¨çš„ä»»åŠ¡äº‹ä»¶ï¼ˆç¡®ä¿åˆ†æ®µä»»åŠ¡æ­£ç¡®å¤„ç†ï¼‰"""
        end_time = start_time
        sub_schedule = []
        
        if task.is_segmented:
            current_time = start_time
            # åˆ†æ®µä»»åŠ¡å¿…é¡»æŒ‰é¡ºåºæ‰§è¡Œæ¯ä¸ªå­æ®µ
            for seg in task.segments:
                if seg.is_segmented and seg.sub_segments:
                    # å¤„ç†å·²åˆ†æ®µçš„segment
                    for sub_seg in seg.sub_segments:
                        if sub_seg.resource_type in resources:
                            duration = sub_seg.get_duration(40.0)
                            sub_schedule.append((sub_seg.sub_id, current_time, current_time + duration))
                            current_time += duration
                            end_time = current_time
                else:
                    # æœªåˆ†æ®µçš„segment
                    if seg.resource_type in resources:
                        duration = seg.get_duration(40.0)
                        sub_schedule.append((f"{seg.segment_id}_0", current_time, current_time + duration))
                        current_time += duration
                        end_time = current_time
            
            # å¯¹äºæ··åˆä»»åŠ¡ï¼ˆå¦‚T2ï¼šNPU+DSPï¼‰ï¼Œç¡®ä¿DSPéƒ¨åˆ†åœ¨NPUä¹‹å
            if 'postprocess' in [s[0] for s in sub_schedule]:
                # é‡æ–°æ’åºï¼Œç¡®ä¿postprocessåœ¨æœ€å
                main_parts = [s for s in sub_schedule if 'postprocess' not in s[0]]
                post_parts = [s for s in sub_schedule if 'postprocess' in s[0]]
                
                # è°ƒæ•´postprocessçš„æ—¶é—´
                if main_parts and post_parts:
                    last_main_end = main_parts[-1][2]
                    for i, (sub_id, _, _) in enumerate(post_parts):
                        duration = post_parts[i][2] - post_parts[i][1]
                        new_start = last_main_end
                        post_parts[i] = (sub_id, new_start, new_start + duration)
                        last_main_end = new_start + duration
                        end_time = last_main_end
                
                sub_schedule = main_parts + post_parts
        else:
            # éåˆ†æ®µä»»åŠ¡
            for seg in task.segments:
                if seg.resource_type in resources:
                    duration = seg.get_duration(40.0)
                    seg_start = start_time + seg.start_time
                    seg_end = seg_start + duration
                    end_time = max(end_time, seg_end)
                    sub_schedule.append((f"{seg.segment_id}_0", seg_start, seg_end))
        
        event = TaskScheduleInfo(
            task_id=task.task_id,
            start_time=start_time,
            end_time=end_time,
            assigned_resources=resources,
            actual_latency=end_time - start_time,
            runtime_type=task.runtime_type
        )
        
        if sub_schedule:
            event.sub_segment_schedule = sub_schedule
        
        return event
    
    def _find_npu_gaps_during_dsp_busy(self, schedule: List[TaskScheduleInfo]) -> List[Tuple[float, float]]:
        """æ‰¾å‡ºDSPå¿™ç¢Œæ—¶çš„NPUç©ºéš™"""
        # æ‰¾å‡ºDSPå¿™ç¢Œæ—¶æ®µ
        dsp_busy_periods = []
        for event in schedule:
            task = self.scheduler.tasks.get(event.task_id)
            if not task:
                continue
            
            if hasattr(event, 'sub_segment_schedule'):
                for sub_id, start, end in event.sub_segment_schedule:
                    if 'dsp' in sub_id.lower():
                        dsp_busy_periods.append((start, end))
        
        # å¯¹æ¯ä¸ªDSPå¿™ç¢Œæ—¶æ®µï¼Œæ£€æŸ¥NPUæ˜¯å¦ç©ºé—²
        npu_gaps = []
        for dsp_start, dsp_end in dsp_busy_periods:
            # åœ¨è¿™ä¸ªDSPæ—¶æ®µå†…æŸ¥æ‰¾NPUç©ºéš™
            npu_free_start = dsp_start
            npu_free_end = dsp_end
            
            # æ£€æŸ¥NPUå ç”¨æƒ…å†µ
            for res_start, res_end, _ in self.resource_busy_times.get('NPU_0', []):
                if res_start <= dsp_start and res_end >= dsp_end:
                    # NPUå®Œå…¨å ç”¨è¿™ä¸ªæ—¶æ®µ
                    npu_free_start = npu_free_end = 0
                    break
                elif res_start <= dsp_start < res_end < dsp_end:
                    # éƒ¨åˆ†é‡å ï¼Œè°ƒæ•´å¼€å§‹æ—¶é—´
                    npu_free_start = max(npu_free_start, res_end)
                elif dsp_start < res_start < dsp_end <= res_end:
                    # éƒ¨åˆ†é‡å ï¼Œè°ƒæ•´ç»“æŸæ—¶é—´
                    npu_free_end = min(npu_free_end, res_start)
                elif dsp_start < res_start < res_end < dsp_end:
                    # NPUå ç”¨åœ¨ä¸­é—´ï¼Œå–å‰åŠéƒ¨åˆ†
                    npu_free_end = res_start
            
            if npu_free_end > npu_free_start + 0.1:  # è‡³å°‘0.1msçš„ç©ºéš™æ‰æœ‰æ„ä¹‰
                npu_gaps.append((npu_free_start, npu_free_end))
        
        # åˆå¹¶ç›¸é‚»ç©ºéš™
        if npu_gaps:
            npu_gaps.sort()
            merged_gaps = []
            current_start, current_end = npu_gaps[0]
            
            for start, end in npu_gaps[1:]:
                if start <= current_end + 0.1:
                    current_end = max(current_end, end)
                else:
                    merged_gaps.append((current_start, current_end))
                    current_start, current_end = start, end
            
            merged_gaps.append((current_start, current_end))
            return merged_gaps
        
        return []
    
    # å…¶ä»–å¿…è¦çš„è¾…åŠ©æ–¹æ³•
    def _compact_schedule(self, schedule: List[TaskScheduleInfo]) -> Tuple[List[TaskScheduleInfo], float]:
        """ä½¿ç”¨DebugCompactorè¿›è¡Œç´§å‡‘åŒ–"""
        self.scheduler.schedule_history = copy.deepcopy(schedule)
        compactor = DebugCompactor(self.scheduler, self.time_window)
        compacted_events, idle_time = compactor.simple_compact()
        return compacted_events, idle_time
    
    def _rebuild_resource_timeline(self, schedule: List[TaskScheduleInfo]):
        """é‡å»ºèµ„æºå ç”¨æ—¶é—´çº¿"""
        self.resource_busy_times.clear()
        
        for event in schedule:
            self._update_resource_timeline(event, self.scheduler.tasks.get(event.task_id))
    
    def _update_resource_timeline(self, event: TaskScheduleInfo, task: Optional[NNTask]):
        """æ›´æ–°èµ„æºæ—¶é—´çº¿"""
        if not task:
            return
            
        if hasattr(event, 'sub_segment_schedule') and event.sub_segment_schedule:
            for sub_id, start, end in event.sub_segment_schedule:
                # é€šè¿‡sub_idç¡®å®šèµ„æºç±»å‹
                for sub_seg in task.get_sub_segments_for_scheduling():
                    if sub_seg.sub_id == sub_id:
                        res_type = sub_seg.resource_type
                        if res_type in event.assigned_resources:
                            res_id = event.assigned_resources[res_type]
                            # æ·»åŠ åˆ°æ—¶é—´çº¿å¹¶ä¿æŒæ’åº
                            if res_id not in self.resource_busy_times:
                                self.resource_busy_times[res_id] = []
                            self.resource_busy_times[res_id].append((start, end, event.task_id))
                            self.resource_busy_times[res_id].sort()
                        break
    
    def _find_tasks_needing_more_runs(self, schedule: List[TaskScheduleInfo]) -> Dict[str, Dict]:
        """æ‰¾å‡ºéœ€è¦æ›´å¤šæ‰§è¡Œçš„ä»»åŠ¡"""
        task_counts = defaultdict(int)
        for event in schedule:
            task_counts[event.task_id] += 1
        
        tasks_needing_runs = {}
        for task_id, task in self.scheduler.tasks.items():
            expected = int((self.time_window / 1000.0) * task.fps_requirement)
            actual = task_counts[task_id]
            if actual < expected:
                tasks_needing_runs[task_id] = {
                    'task': task,
                    'needed': expected - actual,
                    'current': actual,
                    'expected': expected
                }
        
        return tasks_needing_runs
    
    def _allocate_resources(self, task: NNTask) -> Dict[ResourceType, str]:
        """ä¸ºä»»åŠ¡åˆ†é…èµ„æº"""
        resources = {}
        for seg in task.segments:
            res_list = self.scheduler.resources.get(seg.resource_type, [])
            if res_list:
                resources[seg.resource_type] = res_list[0].unit_id
        return resources
    
    def _check_all_fps_satisfied(self, schedule: List[TaskScheduleInfo]) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä»»åŠ¡éƒ½æ»¡è¶³FPSè¦æ±‚"""
        task_counts = defaultdict(int)
        for event in schedule:
            task_counts[event.task_id] += 1
        
        for task_id, task in self.scheduler.tasks.items():
            expected = int((self.time_window / 1000.0) * task.fps_requirement)
            actual = task_counts[task_id]
            if actual < expected * 0.95:  # 95%å®¹å¿åº¦
                return False
        return True
    
    def _print_fps_status(self, schedule: List[TaskScheduleInfo], stage_name: str):
        """æ‰“å°FPSçŠ¶æ€"""
        print(f"\n  {stage_name} FPSçŠ¶æ€:")
        task_counts = defaultdict(int)
        for event in schedule:
            task_counts[event.task_id] += 1
        
        unsatisfied = []
        for task_id in sorted(self.scheduler.tasks.keys()):
            task = self.scheduler.tasks[task_id]
            expected = int((self.time_window / 1000.0) * task.fps_requirement)
            actual = task_counts[task_id]
            fps_rate = actual / expected if expected > 0 else 1.0
            
            if fps_rate < 0.95:
                unsatisfied.append(f"{task_id}:{actual}/{expected}({fps_rate:.0%})")
        
        if unsatisfied:
            print(f"    æœªè¾¾æ ‡: {', '.join(unsatisfied)}")
        else:
            print(f"    âœ… æ‰€æœ‰ä»»åŠ¡è¾¾æ ‡")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 80)
    print("ğŸš€ æ— å†²çªçš„å®Œæ•´è°ƒåº¦ä¼˜åŒ–æµ‹è¯•")
    print("=" * 80)
    
    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = MultiResourceScheduler(enable_segmentation=True)
    scheduler.add_npu("NPU_0", bandwidth=40.0)
    scheduler.add_dsp("DSP_0", bandwidth=40.0)
    
    # åº”ç”¨åŸºç¡€ä¿®å¤
    print("\nåº”ç”¨è°ƒåº¦ä¿®å¤...")
    apply_basic_fixes(scheduler)
    
    # åˆ›å»ºä»»åŠ¡
    print("\nåˆ›å»ºçœŸå®ä»»åŠ¡...")
    tasks = create_real_tasks()
    for task in tasks:
        scheduler.add_task(task)
    
    # åº”ç”¨é¢å¤–ä¿®å¤
    apply_minimal_fifo_fix(scheduler)
    apply_strict_resource_conflict_fix(scheduler)
    
    # åˆ›å»ºæ— å†²çªä¼˜åŒ–å™¨å¹¶æ‰§è¡Œä¼˜åŒ–
    optimizer = ConflictFreeOptimizer(scheduler, 200.0)
    final_schedule = optimizer.optimize_complete(max_iterations=3)
    
    # æ›´æ–°è°ƒåº¦å™¨
    scheduler.schedule_history = final_schedule
    
    # æœ€ç»ˆéªŒè¯
    print("\n" + "=" * 60)
    print("ğŸ“Š æœ€ç»ˆéªŒè¯")
    print("=" * 60)
    
    # éªŒè¯å†²çª
    is_valid, conflicts = validate_schedule_correctly(scheduler)
    print(f"\nèµ„æºå†²çªæ£€æŸ¥: {'âœ… æ— å†²çª' if is_valid else f'âŒ {len(conflicts)}ä¸ªå†²çª'}")
    if not is_valid:
        print("å†²çªè¯¦æƒ…:")
        for conflict in conflicts[:5]:
            print(f"  - {conflict}")
    
    # éªŒè¯FPS
    print("\næœ€ç»ˆFPSè¾¾æˆæƒ…å†µ:")
    task_counts = defaultdict(int)
    for event in scheduler.schedule_history:
        task_counts[event.task_id] += 1
    
    all_satisfied = True
    for task_id in sorted(scheduler.tasks.keys()):
        task = scheduler.tasks[task_id]
        expected = int((200.0 / 1000.0) * task.fps_requirement)
        actual = task_counts[task_id]
        fps_rate = actual / expected if expected > 0 else 1.0
        status = "âœ…" if fps_rate >= 0.95 else "âŒ"
        if fps_rate < 0.95:
            all_satisfied = False
        print(f"  {status} {task_id} ({task.name}): {actual}/{expected} ({fps_rate:.1%})")
    
    # è®¡ç®—æœ€ç»ˆç©ºé—²æ—¶é—´
    if scheduler.schedule_history:
        last_end = max(e.end_time for e in scheduler.schedule_history)
        final_idle = 200.0 - last_end
        print(f"\næœ€ç»ˆç©ºé—²æ—¶é—´: {final_idle:.1f}ms ({final_idle/200.0*100:.1f}%)")
    
    # ç”Ÿæˆå¯è§†åŒ–
    print("\nç”Ÿæˆå¯è§†åŒ–...")
    viz = ElegantSchedulerVisualizer(scheduler)
    plt.figure(figsize=(20, 10))
    viz.plot_elegant_gantt(time_window=200.0, show_all_labels=True)
    plt.title('Conflict-Free Optimized Schedule', fontsize=16, pad=20)
    plt.savefig('conflict_free_schedule.png', dpi=150, bbox_inches='tight')
    plt.close()
    
    # Chrome trace
    viz.export_chrome_tracing('conflict_free_schedule.json')
    
    print("\nâœ… ä¼˜åŒ–å®Œæˆï¼")
    print(f"\nä¼˜åŒ–ç»“æœ: {'æ‰€æœ‰ä»»åŠ¡FPSè¾¾æ ‡' if all_satisfied else 'ä»æœ‰ä»»åŠ¡æœªè¾¾æ ‡'}")
    print(f"æœ€ç»ˆçŠ¶æ€: {'æ— å†²çª' if is_valid else f'æœ‰{len(conflicts)}ä¸ªå†²çª'}")
    print("\nç”Ÿæˆçš„æ–‡ä»¶ï¼š")
    print("  - conflict_free_schedule.png")
    print("  - conflict_free_schedule.json")


if __name__ == "__main__":
    main()