#!/usr/bin/env python3
"""
æµ‹è¯• hybrid_task åœºæ™¯çš„è°ƒåº¦ä¼˜åŒ–
é…ç½®ï¼šå•DSP + å•NPUï¼Œå¸¦å®½å„40GB/s
é‡ç‚¹å…³æ³¨FPSè¾¾æ ‡å’Œå»¶è¿Ÿè¦æ±‚
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.resource_queue import ResourceQueueManager
from core.schedule_tracer import ScheduleTracer
from core.launcher import TaskLauncher
from core.enhanced_launcher import EnhancedTaskLauncher
from core.executor import ScheduleExecutor
from core.enums import ResourceType, TaskPriority, SegmentationStrategy
from core.evaluator import PerformanceEvaluator
from scenario.hybrid_task import create_real_tasks
from viz.schedule_visualizer import ScheduleVisualizer
import numpy as np


def print_task_requirements(tasks):
    """æ‰“å°ä»»åŠ¡è¦æ±‚æ¦‚è§ˆ"""
    print("\nğŸ“‹ ä»»åŠ¡è¦æ±‚æ¦‚è§ˆ:")
    print("=" * 100)
    print(f"{'ID':<6} {'åç§°':<15} {'ä¼˜å…ˆçº§':<10} {'FPSè¦æ±‚':<10} {'å»¶è¿Ÿè¦æ±‚(ms)':<15} {'åˆ†æ®µç­–ç•¥':<20}")
    print("-" * 100)
    
    for task in tasks:
        print(f"{task.task_id:<6} {task.name:<15} {task.priority.name:<10} "
              f"{task.fps_requirement:<10.0f} {task.latency_requirement:<15.1f} "
              f"{task.segmentation_strategy.value:<20}")


def analyze_task_demands(tasks, time_window=1000.0):
    """åˆ†æä»»åŠ¡çš„èµ„æºéœ€æ±‚"""
    print("\nğŸ“Š èµ„æºéœ€æ±‚åˆ†æ (å¸¦å®½=40GB/s, æ—¶é—´çª—å£=1000ms):")
    print("=" * 100)
    
    total_npu_demand = 0.0
    total_dsp_demand = 0.0
    
    for task in tasks:
        # è®¡ç®—åœ¨æ—¶é—´çª—å£å†…éœ€è¦çš„å®ä¾‹æ•°
        instances_needed = task.fps_requirement * (time_window / 1000.0)
        
        # è·å–åˆ†æ®µåçš„æ‰§è¡Œæ—¶é—´
        segments = task.apply_segmentation()
        if not segments:
            segments = task.segments
        
        npu_time_per_instance = 0.0
        dsp_time_per_instance = 0.0
        
        for seg in segments:
            duration = seg.get_duration(40.0)  # 40GB/så¸¦å®½
            if seg.resource_type == ResourceType.NPU:
                npu_time_per_instance += duration
            elif seg.resource_type == ResourceType.DSP:
                dsp_time_per_instance += duration
        
        npu_demand = npu_time_per_instance * instances_needed
        dsp_demand = dsp_time_per_instance * instances_needed
        
        total_npu_demand += npu_demand
        total_dsp_demand += dsp_demand
        
        if npu_demand > 0 or dsp_demand > 0:
            print(f"{task.task_id} ({task.name}): "
                  f"NPU={npu_demand:.1f}ms, DSP={dsp_demand:.1f}ms "
                  f"({instances_needed:.1f}å®ä¾‹)")
    
    print(f"\næ€»éœ€æ±‚: NPU={total_npu_demand:.1f}ms, DSP={total_dsp_demand:.1f}ms")
    print(f"ç†è®ºåˆ©ç”¨ç‡: NPU={total_npu_demand/10:.1f}%, DSP={total_dsp_demand/10:.1f}%")
    
    if total_npu_demand > time_window or total_dsp_demand > time_window:
        print("\nâš ï¸ è­¦å‘Š: èµ„æºéœ€æ±‚è¶…è¿‡å¯ç”¨æ—¶é—´ï¼Œéƒ¨åˆ†ä»»åŠ¡å¯èƒ½æ— æ³•æ»¡è¶³FPSè¦æ±‚ï¼")


def test_scheduling_modes(time_window=1000.0):
    """æµ‹è¯•ä¸åŒçš„è°ƒåº¦æ¨¡å¼"""
    print(f"\n\nğŸ”¬ è°ƒåº¦æ¨¡å¼å¯¹æ¯”æµ‹è¯• (æ—¶é—´çª—å£: {time_window}ms)")
    print("=" * 100)
    
    # åˆ›å»ºèµ„æº
    queue_manager = ResourceQueueManager()
    queue_manager.add_resource("NPU_0", ResourceType.NPU, 40.0)
    queue_manager.add_resource("DSP_0", ResourceType.DSP, 40.0)
    
    # å‡†å¤‡ä»»åŠ¡
    tasks = create_real_tasks()
    
    results = {}
    
    # æµ‹è¯•ä¸¤ç§æ¨¡å¼
    modes = [
        ("ä¼ ç»Ÿæ¨¡å¼", False),
        ("æ®µçº§æ¨¡å¼", True)
    ]
    
    for mode_name, segment_mode in modes:
        print(f"\n\n{'='*50}")
        print(f"æ‰§è¡Œ {mode_name} (segment_mode={segment_mode})")
        print('='*50)
        
        # é‡ç½®ç¯å¢ƒ
        queue_manager = ResourceQueueManager()
        queue_manager.add_resource("NPU_0", ResourceType.NPU, 40.0)
        queue_manager.add_resource("DSP_0", ResourceType.DSP, 40.0)
        
        tracer = ScheduleTracer(queue_manager)
        
        if segment_mode:
            launcher = EnhancedTaskLauncher(queue_manager, tracer)
        else:
            launcher = TaskLauncher(queue_manager, tracer)
        
        # æ³¨å†Œä»»åŠ¡
        for task in tasks:
            launcher.register_task(task)
        
        # åˆ›å»ºå‘å°„è®¡åˆ’
        plan = launcher.create_launch_plan(time_window, "eager")
        
        # æ‰§è¡Œ
        executor = ScheduleExecutor(queue_manager, tracer, launcher.tasks)
        stats = executor.execute_plan(plan, time_window, segment_mode=segment_mode)
        
        # è¯„ä¼°æ€§èƒ½
        evaluator = PerformanceEvaluator(tracer, launcher.tasks, queue_manager)
        metrics = evaluator.evaluate(time_window, plan.events)
        
        results[mode_name] = {
            'stats': stats,
            'metrics': metrics,
            'tracer': tracer,
            'evaluator': evaluator
        }
        
        # æ‰“å°ç»“æœæ‘˜è¦
        print(f"\n{mode_name}ç»“æœ:")
        print(f"  å®Œæˆå®ä¾‹: {stats.get('completed_instances', 0)}/{stats.get('total_instances', 0)}")
        # æ‰§è¡Œæ®µæ•°ç»Ÿè®¡
        if 'total_segments_executed' in stats:
            print(f"  æ‰§è¡Œæ®µæ•°: {stats['total_segments_executed']}")
        print(f"  å¹³å‡å»¶è¿Ÿ: {metrics.avg_latency:.1f}ms")
        print(f"  æœ€å¤§å»¶è¿Ÿ: {metrics.max_latency:.1f}ms")
        print(f"  NPUåˆ©ç”¨ç‡: {metrics.avg_npu_utilization:.1f}%")
        print(f"  DSPåˆ©ç”¨ç‡: {metrics.avg_dsp_utilization:.1f}%")
    
    return results


def analyze_latency_performance(results):
    """åˆ†æå»¶è¿Ÿæ€§èƒ½"""
    print("\n\nğŸ“ˆ å»¶è¿Ÿæ€§èƒ½åˆ†æ")
    print("=" * 100)
    
    for mode_name, data in results.items():
        evaluator = data['evaluator']
        
        print(f"\n{mode_name}:")
        print(f"{'ä»»åŠ¡ID':<8} {'ä»»åŠ¡å':<15} {'FPSè¦æ±‚':<10} {'å®é™…FPS':<10} "
              f"{'å»¶è¿Ÿè¦æ±‚':<12} {'å¹³å‡å»¶è¿Ÿ':<12} {'æœ€å¤§å»¶è¿Ÿ':<12} {'æ»¡è¶³ç‡':<10}")
        print("-" * 100)
        
        for task_id, metrics in evaluator.task_metrics.items():
            # è·å–å¯¹åº”çš„ä»»åŠ¡å¯¹è±¡
            task = next((t for t in evaluator.tasks.values() if t.task_id == task_id), None)
            if not task:
                continue
            
            fps_status = "âœ“" if metrics.fps_satisfaction else "âœ—"
            latency_status = "âœ“" if metrics.latency_satisfaction_rate > 0.9 else "âœ—"
            
            print(f"{task_id:<8} {task.name:<15} {metrics.fps_requirement:<10.0f} "
                  f"{metrics.achieved_fps:<9.1f}{fps_status} "
                  f"{metrics.latency_requirement:<12.1f} {metrics.avg_latency:<12.1f} "
                  f"{metrics.max_latency:<12.1f} {metrics.latency_satisfaction_rate:<9.1%}{latency_status}")


def print_detailed_task_analysis(results, task_id):
    """æ‰“å°ç‰¹å®šä»»åŠ¡çš„è¯¦ç»†åˆ†æ"""
    print(f"\n\nğŸ” ä»»åŠ¡ {task_id} è¯¦ç»†åˆ†æ")
    print("=" * 80)
    
    for mode_name, data in results.items():
        evaluator = data['evaluator']
        tracer = data['tracer']
        
        if task_id not in evaluator.task_metrics:
            continue
            
        metrics = evaluator.task_metrics[task_id]
        task = next((t for t in evaluator.tasks.values() if t.task_id == task_id), None)
        if not task:
            continue
        
        print(f"\n{mode_name}:")
        print(f"  ä»»åŠ¡: {task.name}")
        print(f"  å®ä¾‹æ•°: {metrics.instance_count}")
        print(f"  FPS: è¦æ±‚={metrics.fps_requirement}, å®é™…={metrics.achieved_fps:.1f}")
        print(f"  å»¶è¿Ÿ: è¦æ±‚={metrics.latency_requirement:.1f}ms")
        
        if metrics.latencies:
            print(f"    å¹³å‡={metrics.avg_latency:.1f}ms")
            print(f"    æœ€å¤§={metrics.max_latency:.1f}ms")
            print(f"    æœ€å°={min(metrics.latencies):.1f}ms")
            print(f"    æ ‡å‡†å·®={np.std(metrics.latencies):.1f}ms")
            
            # æ˜¾ç¤ºå»¶è¿Ÿåˆ†å¸ƒ
            print(f"  å»¶è¿Ÿåˆ†å¸ƒ:")
            bins = [0, 25, 50, 75, 100, 150, 200, float('inf')]
            bin_labels = ['0-25', '25-50', '50-75', '75-100', '100-150', '150-200', '>200']
            bin_counts = [0] * (len(bins) - 1)
            
            for latency in metrics.latencies:
                for i in range(len(bins) - 1):
                    if bins[i] <= latency < bins[i+1]:
                        bin_counts[i] += 1
                        break
            
            for label, count in zip(bin_labels, bin_counts):
                if count > 0:
                    percentage = (count / len(metrics.latencies)) * 100
                    print(f"    {label}ms: {count} ({percentage:.1f}%)")


def visualize_execution(results, time_range=(0, 200)):
    """å¯è§†åŒ–æ‰§è¡Œæ—¶é—´çº¿"""
    print(f"\n\nğŸ“Š æ‰§è¡Œæ—¶é—´çº¿å¯è§†åŒ–")
    print("=" * 100)
    
    for mode_name, data in results.items():
        tracer = data['tracer']
        visualizer = ScheduleVisualizer(tracer)
        
        print(f"\n{mode_name}:")
        # ç›´æ¥ä½¿ç”¨é»˜è®¤çš„ç”˜ç‰¹å›¾æ˜¾ç¤º
        visualizer.print_gantt_chart(width=80)
        
        # ç”Ÿæˆå›¾ç‰‡
        png_filename = f"hybrid_task_{mode_name.replace(' ', '_')}.png"
        visualizer.plot_resource_timeline(png_filename)
        print(f"  âœ“ ç”Ÿæˆç”˜ç‰¹å›¾: {png_filename}")
        
        # ç”ŸæˆChrome Tracing JSONæ–‡ä»¶
        json_filename = f"hybrid_task_{mode_name.replace(' ', '_')}_trace.json"
        visualizer.export_chrome_tracing(json_filename)
        print(f"  âœ“ ç”ŸæˆChrome Tracingæ–‡ä»¶: {json_filename}")
    
    print("\nğŸ’¡ æç¤ºï¼šåœ¨Chromeæµè§ˆå™¨ä¸­æ‰“å¼€ chrome://tracing å¹¶åŠ è½½JSONæ–‡ä»¶æŸ¥çœ‹è¯¦ç»†æ—¶é—´çº¿")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 100)
    print("Hybrid Task è°ƒåº¦ä¼˜åŒ–æµ‹è¯•")
    print("é…ç½®: å•DSP + å•NPU, å¸¦å®½å„40GB/s")
    print("=" * 100)
    
    # 1. åˆ›å»ºä»»åŠ¡å¹¶åˆ†æ
    tasks = create_real_tasks()
    print_task_requirements(tasks)
    
    # 2. åˆ†æèµ„æºéœ€æ±‚
    analyze_task_demands(tasks)
    
    # 3. æ‰§è¡Œè°ƒåº¦æµ‹è¯•
    results = test_scheduling_modes(time_window=1000.0)
    
    # 4. åˆ†æå»¶è¿Ÿæ€§èƒ½
    analyze_latency_performance(results)
    
    # 5. åˆ†æå…³é”®ä»»åŠ¡çš„è¯¦ç»†æ€§èƒ½
    critical_tasks = ["T11", "T12", "T14"]  # Stereo4x å’Œ Skywater ç³»åˆ—
    for task_id in critical_tasks:
        print_detailed_task_analysis(results, task_id)
    
    # 6. å¯è§†åŒ–å‰200msçš„æ‰§è¡Œ
    visualize_execution(results, time_range=(0, 200))
    
    # 7. æ€»ç»“
    print("\n\n" + "=" * 100)
    print("ğŸ“Š ä¼˜åŒ–æ•ˆæœæ€»ç»“")
    print("=" * 100)
    
    # è®¡ç®—æ”¹è¿›
    old_metrics = results['ä¼ ç»Ÿæ¨¡å¼']['metrics']
    new_metrics = results['æ®µçº§æ¨¡å¼']['metrics']
    
    print("\næ€§èƒ½æ”¹è¿›:")
    print(f"  å¹³å‡å»¶è¿Ÿ: {old_metrics.avg_latency:.1f}ms â†’ {new_metrics.avg_latency:.1f}ms "
          f"(æ”¹å–„ {((old_metrics.avg_latency - new_metrics.avg_latency) / old_metrics.avg_latency * 100):.1f}%)")
    print(f"  æœ€å¤§å»¶è¿Ÿ: {old_metrics.max_latency:.1f}ms â†’ {new_metrics.max_latency:.1f}ms")
    print(f"  NPUåˆ©ç”¨ç‡: {old_metrics.avg_npu_utilization:.1f}% â†’ {new_metrics.avg_npu_utilization:.1f}%")
    print(f"  DSPåˆ©ç”¨ç‡: {old_metrics.avg_dsp_utilization:.1f}% â†’ {new_metrics.avg_dsp_utilization:.1f}%")
    
    # ç»Ÿè®¡å»¶è¿Ÿè¦æ±‚æ»¡è¶³æƒ…å†µ
    trad_satisfied = 0
    seg_satisfied = 0
    
    for task_id in results['ä¼ ç»Ÿæ¨¡å¼']['evaluator'].task_metrics:
        if results['ä¼ ç»Ÿæ¨¡å¼']['evaluator'].task_metrics[task_id].latency_satisfaction_rate > 0.9:
            trad_satisfied += 1
        if results['æ®µçº§æ¨¡å¼']['evaluator'].task_metrics[task_id].latency_satisfaction_rate > 0.9:
            seg_satisfied += 1
    
    total_tasks = len(results['ä¼ ç»Ÿæ¨¡å¼']['evaluator'].task_metrics)
    print(f"\nå»¶è¿Ÿè¦æ±‚æ»¡è¶³æƒ…å†µ:")
    print(f"  ä¼ ç»Ÿæ¨¡å¼: {trad_satisfied}/{total_tasks} ä»»åŠ¡æ»¡è¶³å»¶è¿Ÿè¦æ±‚")
    print(f"  æ®µçº§æ¨¡å¼: {seg_satisfied}/{total_tasks} ä»»åŠ¡æ»¡è¶³å»¶è¿Ÿè¦æ±‚")
    
    print("\nå…³é”®å‘ç°:")
    print("1. æ®µçº§è°ƒåº¦èƒ½å¤Ÿæ˜¾è‘—æ”¹å–„ä»»åŠ¡å»¶è¿Ÿï¼Œç‰¹åˆ«æ˜¯å¯¹äºæœ‰ä¸¥æ ¼å»¶è¿Ÿè¦æ±‚çš„ä»»åŠ¡")
    print("2. é€šè¿‡æ›´çµæ´»çš„è°ƒåº¦ï¼Œå¯ä»¥åœ¨ç›¸åŒèµ„æºä¸‹æ»¡è¶³æ›´å¤šä»»åŠ¡çš„æ€§èƒ½è¦æ±‚")
    print("3. æŸäº›é«˜è´Ÿè½½ä»»åŠ¡å¯èƒ½ä»éœ€è¦é¢å¤–èµ„æºæ‰èƒ½å®Œå…¨æ»¡è¶³è¦æ±‚")


if __name__ == "__main__":
    main()
