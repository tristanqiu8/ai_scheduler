#!/usr/bin/env python3
"""
æµ‹è¯•çœŸå®ä»»åŠ¡åœ¨æ®µçº§æ¨¡å¼ä¸‹çš„ä¼˜åŒ–æ•ˆæœ - ä¿®å¤ç‰ˆæœ¬
ä½¿ç”¨ FORCED_SEGMENTATION ç­–ç•¥å¼ºåˆ¶T2å’ŒT3åˆ†æ®µ
ç¡®ä¿æ‰€æœ‰ä»»åŠ¡éƒ½èƒ½è¾¾åˆ°FPSè¦æ±‚
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.resource_queue import ResourceQueueManager
from core.schedule_tracer import ScheduleTracer
from core.launcher import TaskLauncher
from core.enhanced_launcher import EnhancedTaskLauncher
from core.executor import ScheduleExecutor
from core.enums import ResourceType, TaskPriority, SegmentationStrategy
from core.evaluator import PerformanceEvaluator
from core.models import SubSegment
from scenario.real_task import create_real_tasks
from viz.schedule_visualizer import ScheduleVisualizer
import copy
import numpy as np


def compute_resource_demand(tasks, bandwidth_npu=40.0, bandwidth_dsp=40.0, time_window_ms=1000.0):
    """
    è®¡ç®—åœ¨ç»™å®šå¸¦å®½ä¸‹ï¼ŒæŒ‡å®šæ—¶é—´çª—å£å†…NPUå’ŒDSPçš„æ€»èµ„æºéœ€æ±‚
    
    Args:
        tasks: ä»»åŠ¡åˆ—è¡¨
        bandwidth_npu: NPUå¸¦å®½
        bandwidth_dsp: DSPå¸¦å®½
        time_window_ms: æ—¶é—´çª—å£ï¼ˆæ¯«ç§’ï¼‰
        
    Returns:
        dict: åŒ…å«èµ„æºéœ€æ±‚åˆ†æçš„å­—å…¸
    """
    npu_total_time = 0.0
    dsp_total_time = 0.0
    
    # è¯¦ç»†çš„ä»»åŠ¡éœ€æ±‚
    task_details = []
    
    for task in tasks:
        # è®¡ç®—è¿™ä¸ªä»»åŠ¡åœ¨æ—¶é—´çª—å£å†…éœ€è¦æ‰§è¡Œçš„æ¬¡æ•°
        instances_needed = task.fps_requirement * (time_window_ms / 1000.0)
        
        # åº”ç”¨åˆ†æ®µç­–ç•¥è·å–å®é™…æ‰§è¡Œçš„æ®µ
        segments = task.apply_segmentation()
        if not segments:
            segments = task.segments
        
        # è®¡ç®—æ¯ä¸ªæ®µçš„æ‰§è¡Œæ—¶é—´
        npu_time_per_instance = 0.0
        dsp_time_per_instance = 0.0
        segment_details = []
        
        for seg in segments:
            if seg.resource_type == ResourceType.NPU:
                # è·å–åœ¨æŒ‡å®šå¸¦å®½ä¸‹çš„æ‰§è¡Œæ—¶é—´
                duration = seg.get_duration(bandwidth_npu)
                npu_time_per_instance += duration
                segment_details.append({
                    'segment': seg.sub_id,
                    'resource': 'NPU',
                    'duration': duration
                })
            elif seg.resource_type == ResourceType.DSP:
                duration = seg.get_duration(bandwidth_dsp)
                dsp_time_per_instance += duration
                segment_details.append({
                    'segment': seg.sub_id,
                    'resource': 'DSP',
                    'duration': duration
                })
        
        # è®¡ç®—æ€»æ—¶é—´éœ€æ±‚
        task_npu_total = npu_time_per_instance * instances_needed
        task_dsp_total = dsp_time_per_instance * instances_needed
        
        npu_total_time += task_npu_total
        dsp_total_time += task_dsp_total
        
        task_details.append({
            'task_id': task.task_id,
            'task_name': task.name,
            'fps': task.fps_requirement,
            'instances_in_window': instances_needed,
            'segments': segment_details,
            'npu_time_per_instance': npu_time_per_instance,
            'dsp_time_per_instance': dsp_time_per_instance,
            'npu_total_time': task_npu_total,
            'dsp_total_time': task_dsp_total
        })
    
    # è®¡ç®—èµ„æºåˆ©ç”¨ç‡ï¼ˆè¶…è¿‡100%è¡¨ç¤ºè¿‡è½½ï¼‰
    npu_utilization = (npu_total_time / time_window_ms) * 100
    dsp_utilization = (dsp_total_time / time_window_ms) * 100
    
    return {
        'bandwidth': {
            'npu': bandwidth_npu,
            'dsp': bandwidth_dsp
        },
        'time_window_ms': time_window_ms,
        'total_demand': {
            'npu_ms': npu_total_time,
            'dsp_ms': dsp_total_time
        },
        'utilization': {
            'npu_percent': npu_utilization,
            'dsp_percent': dsp_utilization
        },
        'feasible': npu_utilization <= 100 and dsp_utilization <= 100,
        'task_details': task_details
    }


def print_resource_demand_analysis(tasks, bandwidth_npu=40.0, bandwidth_dsp=40.0):
    """
    æ‰“å°èµ„æºéœ€æ±‚åˆ†ææŠ¥å‘Š
    
    Args:
        tasks: ä»»åŠ¡åˆ—è¡¨
        bandwidth_npu: NPUå¸¦å®½
        bandwidth_dsp: DSPå¸¦å®½
    """
    print("\n" + "="*80)
    print("ğŸ“Š èµ„æºéœ€æ±‚åˆ†æï¼ˆ1ç§’å†…ï¼‰")
    print("="*80)
    
    analysis = compute_resource_demand(tasks, bandwidth_npu, bandwidth_dsp)
    
    print(f"\né…ç½®:")
    print(f"  NPUå¸¦å®½: {analysis['bandwidth']['npu']} Gbps")
    print(f"  DSPå¸¦å®½: {analysis['bandwidth']['dsp']} Gbps")
    print(f"  æ—¶é—´çª—å£: {analysis['time_window_ms']} ms")
    
    print(f"\næ€»èµ„æºéœ€æ±‚:")
    print(f"  NPUæ€»è€—æ—¶: {analysis['total_demand']['npu_ms']:.1f} ms")
    print(f"  DSPæ€»è€—æ—¶: {analysis['total_demand']['dsp_ms']:.1f} ms")
    
    print(f"\nç†è®ºèµ„æºåˆ©ç”¨ç‡:")
    npu_util = analysis['utilization']['npu_percent']
    dsp_util = analysis['utilization']['dsp_percent']
    print(f"  NPU: {npu_util:.1f}% {'âš ï¸ è¿‡è½½!' if npu_util > 100 else 'âœ“'}")
    print(f"  DSP: {dsp_util:.1f}% {'âš ï¸ è¿‡è½½!' if dsp_util > 100 else 'âœ“'}")
    
    if analysis['feasible']:
        print(f"\nâœ… ç³»ç»Ÿå¯è¡Œï¼šæ‰€æœ‰ä»»åŠ¡çš„FPSè¦æ±‚ç†è®ºä¸Šå¯ä»¥æ»¡è¶³")
    else:
        print(f"\nâŒ ç³»ç»Ÿä¸å¯è¡Œï¼šèµ„æºä¸è¶³ä»¥æ»¡è¶³æ‰€æœ‰ä»»åŠ¡çš„FPSè¦æ±‚")
    
    # æ‰“å°ä»»åŠ¡è¯¦æƒ…
    print(f"\nä»»åŠ¡è¯¦ç»†éœ€æ±‚:")
    print(f"{'ä»»åŠ¡':<15} {'FPS':<6} {'å®ä¾‹/ç§’':<8} {'NPUæ—¶é—´/å®ä¾‹':<12} {'DSPæ—¶é—´/å®ä¾‹':<12} {'NPUæ€»è®¡':<10} {'DSPæ€»è®¡':<10}")
    print("-"*90)
    
    for task in analysis['task_details']:
        print(f"{task['task_id']:<15} {task['fps']:<6} {task['instances_in_window']:<8.1f} "
              f"{task['npu_time_per_instance']:<12.2f} {task['dsp_time_per_instance']:<12.2f} "
              f"{task['npu_total_time']:<10.1f} {task['dsp_total_time']:<10.1f}")
    
    # æ‰¾å‡ºæœ€è€—èµ„æºçš„ä»»åŠ¡
    print(f"\nèµ„æºæ¶ˆè€—TOP3:")
    
    # NPU TOP3
    npu_sorted = sorted(analysis['task_details'], key=lambda x: x['npu_total_time'], reverse=True)[:3]
    print(f"\n  NPUæ¶ˆè€—æœ€å¤šçš„ä»»åŠ¡:")
    for i, task in enumerate(npu_sorted, 1):
        percentage = (task['npu_total_time'] / analysis['total_demand']['npu_ms']) * 100 if analysis['total_demand']['npu_ms'] > 0 else 0
        print(f"    {i}. {task['task_id']}: {task['npu_total_time']:.1f}ms ({percentage:.1f}%)")
    
    # DSP TOP3
    dsp_sorted = sorted(analysis['task_details'], key=lambda x: x['dsp_total_time'], reverse=True)[:3]
    print(f"\n  DSPæ¶ˆè€—æœ€å¤šçš„ä»»åŠ¡:")
    for i, task in enumerate(dsp_sorted, 1):
        if task['dsp_total_time'] > 0:
            percentage = (task['dsp_total_time'] / analysis['total_demand']['dsp_ms']) * 100 if analysis['total_demand']['dsp_ms'] > 0 else 0
            print(f"    {i}. {task['task_id']}: {task['dsp_total_time']:.1f}ms ({percentage:.1f}%)")


def analyze_bandwidth_scenarios(tasks):
    """
    åˆ†æä¸åŒå¸¦å®½åœºæ™¯ä¸‹çš„èµ„æºéœ€æ±‚
    
    Args:
        tasks: ä»»åŠ¡åˆ—è¡¨
    """
    print("\n" + "="*80)
    print("ğŸ“Š ä¸åŒå¸¦å®½åœºæ™¯åˆ†æ")
    print("="*80)
    
    scenarios = [
        ("ä½å¸¦å®½", 30.0, 20.0),
        ("ä¸­å¸¦å®½", 40.0, 40.0),
        ("é«˜å¸¦å®½", 120.0, 80.0),
    ]
    
    for name, npu_bw, dsp_bw in scenarios:
        analysis = compute_resource_demand(tasks, npu_bw, dsp_bw)
        
        print(f"\n{name} (NPU={npu_bw}, DSP={dsp_bw}):")
        print(f"  NPUéœ€æ±‚: {analysis['total_demand']['npu_ms']:.1f}ms ({analysis['utilization']['npu_percent']:.1f}%)")
        print(f"  DSPéœ€æ±‚: {analysis['total_demand']['dsp_ms']:.1f}ms ({analysis['utilization']['dsp_percent']:.1f}%)")
        print(f"  çŠ¶æ€: {'âœ… å¯è¡Œ' if analysis['feasible'] else 'âŒ ä¸å¯è¡Œ'}")


def analyze_execution_gaps(tracer, window_ms=200.0):
    """
    åˆ†æå®é™…æ‰§è¡Œä¸­çš„èµ„æºç©ºé—²æ—¶é—´å’Œåˆ©ç”¨ç‡å·®å¼‚
    
    Args:
        tracer: ScheduleTracerå¯¹è±¡
        window_ms: åˆ†æçª—å£ï¼ˆæ¯«ç§’ï¼‰
    
    Returns:
        dict: åŒ…å«è¯¦ç»†åˆ†æçš„å­—å…¸
    """
    resource_timelines = {}
    
    # åˆå§‹åŒ–æ¯ä¸ªèµ„æºçš„æ—¶é—´çº¿
    for res_id in tracer.queue_manager.resource_queues.keys():
        resource_timelines[res_id] = {
            'busy_periods': [],
            'gaps': [],
            'total_busy_time': 0.0,
            'total_gap_time': 0.0,
            'task_executions': []
        }
    
    # æ”¶é›†æ‰§è¡Œä¿¡æ¯
    for exec in tracer.executions:
        if exec.resource_id in resource_timelines:
            timeline = resource_timelines[exec.resource_id]
            timeline['busy_periods'].append((exec.start_time, exec.end_time))
            timeline['task_executions'].append({
                'task_id': exec.task_id,
                'start': exec.start_time,
                'end': exec.end_time,
                'duration': exec.duration,
                'priority': exec.priority.name
            })
    
    # åˆ†ææ¯ä¸ªèµ„æº
    for res_id, timeline in resource_timelines.items():
        # æ’åºå¿™ç¢ŒæœŸé—´
        timeline['busy_periods'].sort()
        
        # è®¡ç®—æ€»å¿™ç¢Œæ—¶é—´
        for start, end in timeline['busy_periods']:
            timeline['total_busy_time'] += (end - start)
        
        # æ‰¾å‡ºç©ºé—²æœŸé—´
        if timeline['busy_periods']:
            # å¼€å§‹å‰çš„ç©ºé—²
            if timeline['busy_periods'][0][0] > 0:
                gap_duration = timeline['busy_periods'][0][0]
                timeline['gaps'].append({
                    'start': 0,
                    'end': timeline['busy_periods'][0][0],
                    'duration': gap_duration,
                    'reason': 'startup_delay'
                })
                timeline['total_gap_time'] += gap_duration
            
            # ä¸­é—´çš„ç©ºé—²
            for i in range(len(timeline['busy_periods']) - 1):
                gap_start = timeline['busy_periods'][i][1]
                gap_end = timeline['busy_periods'][i+1][0]
                if gap_end > gap_start:
                    gap_duration = gap_end - gap_start
                    timeline['gaps'].append({
                        'start': gap_start,
                        'end': gap_end,
                        'duration': gap_duration,
                        'reason': 'scheduling_gap'
                    })
                    timeline['total_gap_time'] += gap_duration
            
            # ç»“æŸåçš„ç©ºé—²
            last_end = timeline['busy_periods'][-1][1]
            if last_end < window_ms:
                gap_duration = window_ms - last_end
                timeline['gaps'].append({
                    'start': last_end,
                    'end': window_ms,
                    'duration': gap_duration,
                    'reason': 'end_idle'
                })
                timeline['total_gap_time'] += gap_duration
        else:
            # å®Œå…¨ç©ºé—²
            timeline['gaps'].append({
                'start': 0,
                'end': window_ms,
                'duration': window_ms,
                'reason': 'completely_idle'
            })
            timeline['total_gap_time'] = window_ms
        
        # è®¡ç®—åˆ©ç”¨ç‡
        timeline['utilization_percent'] = (timeline['total_busy_time'] / window_ms) * 100
        timeline['gap_percent'] = (timeline['total_gap_time'] / window_ms) * 100
    
    return resource_timelines


def print_execution_gap_analysis(tracer, window_ms=200.0):
    """
    æ‰“å°æ‰§è¡Œç©ºéš™åˆ†ææŠ¥å‘Š
    
    Args:
        tracer: ScheduleTracerå¯¹è±¡
        window_ms: åˆ†æçª—å£ï¼ˆæ¯«ç§’ï¼‰
    """
    print("\n" + "="*80)
    print("ğŸ“Š æ‰§è¡Œç©ºéš™åˆ†æ")
    print("="*80)
    
    analysis = analyze_execution_gaps(tracer, window_ms)
    
    # æ‰“å°æ¯ä¸ªèµ„æºçš„åˆ†æ
    for res_id in sorted(analysis.keys()):
        timeline = analysis[res_id]
        
        print(f"\n{res_id}:")
        print(f"  æ€»å¿™ç¢Œæ—¶é—´: {timeline['total_busy_time']:.1f}ms")
        print(f"  æ€»ç©ºé—²æ—¶é—´: {timeline['total_gap_time']:.1f}ms")
        print(f"  åˆ©ç”¨ç‡: {timeline['utilization_percent']:.1f}%")
        print(f"  ç©ºé—²ç‡: {timeline['gap_percent']:.1f}%")
        
        # æ‰“å°ä¸»è¦ç©ºéš™
        if timeline['gaps']:
            print(f"\n  ä¸»è¦ç©ºéš™ (>1ms):")
            significant_gaps = [g for g in timeline['gaps'] if g['duration'] > 1.0]
            for gap in sorted(significant_gaps, key=lambda x: x['duration'], reverse=True)[:5]:
                print(f"    {gap['start']:>6.1f} - {gap['end']:>6.1f}ms: "
                      f"{gap['duration']:>5.1f}ms ({gap['reason']})")
        
        # ä»»åŠ¡æ‰§è¡Œç»Ÿè®¡
        if timeline['task_executions']:
            print(f"\n  ä»»åŠ¡æ‰§è¡Œæ¬¡æ•°: {len(timeline['task_executions'])}")
            # æŒ‰ä»»åŠ¡IDç»Ÿè®¡
            task_counts = {}
            for exec in timeline['task_executions']:
                task_base = exec['task_id'].split('#')[0]
                task_counts[task_base] = task_counts.get(task_base, 0) + 1
            
            print(f"  ä»»åŠ¡åˆ†å¸ƒ:")
            for task_id, count in sorted(task_counts.items()):
                print(f"    {task_id}: {count}æ¬¡")
    
    # æ€»ä½“ç»Ÿè®¡
    total_busy = sum(t['total_busy_time'] for t in analysis.values())
    total_gap = sum(t['total_gap_time'] for t in analysis.values())
    num_resources = len(analysis)
    
    print(f"\næ€»ä½“ç»Ÿè®¡:")
    print(f"  èµ„æºæ•°: {num_resources}")
    print(f"  æ€»å¿™ç¢Œæ—¶é—´: {total_busy:.1f}ms")
    print(f"  æ€»ç©ºé—²æ—¶é—´: {total_gap:.1f}ms")
    print(f"  å¹³å‡åˆ©ç”¨ç‡: {(total_busy / (window_ms * num_resources)) * 100:.1f}%")
    
    # åˆ†æç©ºéš™åŸå› 
    gap_reasons = {}
    for timeline in analysis.values():
        for gap in timeline['gaps']:
            reason = gap['reason']
            if reason not in gap_reasons:
                gap_reasons[reason] = {'count': 0, 'total_time': 0}
            gap_reasons[reason]['count'] += 1
            gap_reasons[reason]['total_time'] += gap['duration']
    
    if gap_reasons:
        print(f"\nç©ºéš™åŸå› åˆ†æ:")
        for reason, stats in sorted(gap_reasons.items(), key=lambda x: x[1]['total_time'], reverse=True):
            avg_duration = stats['total_time'] / stats['count'] if stats['count'] > 0 else 0
            print(f"  {reason}: {stats['count']}æ¬¡, "
                  f"æ€»è®¡{stats['total_time']:.1f}ms, "
                  f"å¹³å‡{avg_duration:.1f}ms/æ¬¡")


def compare_theory_vs_actual(tasks, tracer, bandwidth_npu=40.0, bandwidth_dsp=40.0, window_ms=200.0):
    """
    æ¯”è¾ƒç†è®ºéœ€æ±‚å’Œå®é™…æ‰§è¡Œçš„å·®å¼‚
    
    Args:
        tasks: ä»»åŠ¡åˆ—è¡¨
        tracer: ScheduleTracerå¯¹è±¡
        bandwidth_npu: NPUå¸¦å®½
        bandwidth_dsp: DSPå¸¦å®½
        window_ms: æ—¶é—´çª—å£
    """
    print("\n" + "="*80)
    print("ğŸ“Š ç†è®º vs å®é™…æ‰§è¡Œå¯¹æ¯”")
    print("="*80)
    
    # è®¡ç®—ç†è®ºéœ€æ±‚ï¼ˆæŒ‰æ¯”ä¾‹ç¼©æ”¾åˆ°å®é™…çª—å£ï¼‰
    theory_1s = compute_resource_demand(tasks, bandwidth_npu, bandwidth_dsp, 1000.0)
    theory_window = compute_resource_demand(tasks, bandwidth_npu, bandwidth_dsp, window_ms)
    
    # è·å–å®é™…æ‰§è¡Œç»Ÿè®¡
    actual_stats = tracer.get_statistics()
    gap_analysis = analyze_execution_gaps(tracer, window_ms)
    
    print(f"\næ—¶é—´çª—å£: {window_ms}ms")
    
    print(f"\nç†è®ºéœ€æ±‚ (1ç§’å†…):")
    print(f"  NPU: {theory_1s['total_demand']['npu_ms']:.1f}ms ({theory_1s['utilization']['npu_percent']:.1f}%)")
    print(f"  DSP: {theory_1s['total_demand']['dsp_ms']:.1f}ms ({theory_1s['utilization']['dsp_percent']:.1f}%)")
    
    print(f"\nç†è®ºéœ€æ±‚ ({window_ms}mså†…):")
    print(f"  NPU: {theory_window['total_demand']['npu_ms']:.1f}ms ({theory_window['utilization']['npu_percent']:.1f}%)")
    print(f"  DSP: {theory_window['total_demand']['dsp_ms']:.1f}ms ({theory_window['utilization']['dsp_percent']:.1f}%)")
    
    print(f"\nå®é™…æ‰§è¡Œ:")
    if 'NPU_0' in gap_analysis:
        actual_npu_time = gap_analysis['NPU_0']['total_busy_time']
        actual_npu_util = gap_analysis['NPU_0']['utilization_percent']
        print(f"  NPU_0: {actual_npu_time:.1f}ms ({actual_npu_util:.1f}%)")
    
    if 'DSP_0' in gap_analysis:
        actual_dsp_time = gap_analysis['DSP_0']['total_busy_time']
        actual_dsp_util = gap_analysis['DSP_0']['utilization_percent']
        print(f"  DSP_0: {actual_dsp_time:.1f}ms ({actual_dsp_util:.1f}%)")
    
    # å·®å¼‚åˆ†æ
    print(f"\nå·®å¼‚åˆ†æ:")
    if 'NPU_0' in gap_analysis:
        theory_npu = theory_window['total_demand']['npu_ms']
        actual_npu = gap_analysis['NPU_0']['total_busy_time']
        diff_npu = actual_npu - theory_npu
        print(f"  NPUå·®å¼‚: {diff_npu:+.1f}ms ({(diff_npu/theory_npu*100) if theory_npu > 0 else 0:+.1f}%)")
        
        # åˆ†æå·®å¼‚åŸå› 
        if abs(diff_npu) > 1:
            print(f"    å¯èƒ½åŸå› :")
            startup_gap = next((g for g in gap_analysis['NPU_0']['gaps'] if g['reason'] == 'startup_delay'), None)
            if startup_gap:
                print(f"    - å¯åŠ¨å»¶è¿Ÿ: ~{startup_gap['duration']:.1f}ms")
            scheduling_gaps = sum(g['duration'] for g in gap_analysis['NPU_0']['gaps'] 
                                if g['reason'] == 'scheduling_gap')
            if scheduling_gaps > 0:
                print(f"    - è°ƒåº¦é—´éš™: ~{scheduling_gaps:.1f}ms")
    
    if 'DSP_0' in gap_analysis:
        theory_dsp = theory_window['total_demand']['dsp_ms']
        actual_dsp = gap_analysis['DSP_0']['total_busy_time']
        diff_dsp = actual_dsp - theory_dsp
        print(f"  DSPå·®å¼‚: {diff_dsp:+.1f}ms ({(diff_dsp/theory_dsp*100) if theory_dsp > 0 else 0:+.1f}%)")


def calculate_system_utilization(tracer, window_size):
    """è®¡ç®—ç³»ç»Ÿåˆ©ç”¨ç‡ï¼ˆè‡³å°‘æœ‰ä¸€ä¸ªç¡¬ä»¶å•å…ƒå¿™ç¢Œçš„æ—¶é—´æ¯”ä¾‹ï¼‰"""
    busy_intervals = []
    
    # æ”¶é›†æ‰€æœ‰æ‰§è¡Œæ—¶é—´æ®µ
    for exec in tracer.executions:
        if exec.start_time is not None and exec.end_time is not None:
            busy_intervals.append((exec.start_time, exec.end_time))
    
    if not busy_intervals:
        return 0.0
    
    # åˆå¹¶é‡å çš„æ—¶é—´æ®µ
    busy_intervals.sort()
    merged_intervals = []
    
    for start, end in busy_intervals:
        if merged_intervals and start <= merged_intervals[-1][1]:
            # é‡å ï¼Œæ‰©å±•æœ€åä¸€ä¸ªåŒºé—´
            merged_intervals[-1] = (merged_intervals[-1][0], max(merged_intervals[-1][1], end))
        else:
            # ä¸é‡å ï¼Œæ·»åŠ æ–°åŒºé—´
            merged_intervals.append((start, end))
    
    # è®¡ç®—æ€»å¿™ç¢Œæ—¶é—´
    total_busy_time = sum(end - start for start, end in merged_intervals)
    
    return (total_busy_time / window_size) * 100.0


def prepare_tasks_with_segmentation():
    """å‡†å¤‡ä»»åŠ¡å¹¶è®¾ç½®T2å’ŒT3ä¸ºå¼ºåˆ¶åˆ†æ®µ"""
    tasks = create_real_tasks()
    
    # T2 (YoloV8nBig) - è®¾ç½®ä¸ºå¼ºåˆ¶åˆ†æ®µ
    t2 = tasks[1]
    t2.segmentation_strategy = SegmentationStrategy.FORCED_SEGMENTATION
    
    # T3 (YoloV8nSmall) - è®¾ç½®ä¸ºå¼ºåˆ¶åˆ†æ®µ  
    t3 = tasks[2]
    t3.segmentation_strategy = SegmentationStrategy.FORCED_SEGMENTATION
    
    return tasks


def analyze_segmented_tasks():
    """åˆ†æåˆ†æ®µåçš„ä»»åŠ¡ç‰¹å¾"""
    print("=== åˆ†æ®µç­–ç•¥åˆ†æ ===\n")
    
    tasks = prepare_tasks_with_segmentation()
    
    print(f"{'ä»»åŠ¡ID':<10} {'ä»»åŠ¡åç§°':<20} {'åˆ†æ®µç­–ç•¥':<25} {'åŸæ®µæ•°':>8} {'å­æ®µæ•°':>8} {'FPSè¦æ±‚':>8}")
    print("-" * 85)
    
    for task in tasks[:8]:  # æ˜¾ç¤ºæ‰€æœ‰8ä¸ªä»»åŠ¡
        sub_segments = task.apply_segmentation()
        seg_count = len(sub_segments) if sub_segments else len(task.segments)
        
        print(f"{task.task_id:<10} {task.name:<20} {task.segmentation_strategy.value:<25} "
              f"{len(task.segments):>8} {seg_count:>8} {task.fps_requirement:>8}")
    
    print("\nå…³é”®å˜åŒ–ï¼š")
    print("- T2 (YoloV8nBig): ä½¿ç”¨ FORCED_SEGMENTATIONï¼ŒNPUæ®µè¢«åˆ‡åˆ†")
    print("- T3 (YoloV8nSmall): ä½¿ç”¨ FORCED_SEGMENTATIONï¼ŒNPUæ®µè¢«åˆ‡åˆ†")
    print("- å…¶ä»–ä»»åŠ¡ä¿æŒ NO_SEGMENTATION ç­–ç•¥")


def test_single_npu_dsp_baseline():
    """æµ‹è¯•å•NPU+å•DSPçš„åŸºå‡†æ€§èƒ½"""
    print("\n\n=== åŸºå‡†æµ‹è¯•ï¼šå•NPU + å•DSP (æ‰€æœ‰ä»»åŠ¡) ===\n")
    
    # åˆ›å»ºèµ„æº
    queue_manager = ResourceQueueManager()
    queue_manager.add_resource("NPU_0", ResourceType.NPU, 40.0)
    queue_manager.add_resource("DSP_0", ResourceType.DSP, 40.0)
    
    # å‡†å¤‡åˆ†æ®µåçš„ä»»åŠ¡
    tasks = prepare_tasks_with_segmentation()
    
    # æ‰“å°æ‰€æœ‰ä»»åŠ¡ä¿¡æ¯...ï¼ˆçœç•¥ä¸å˜çš„éƒ¨åˆ†ï¼‰
    
    results = {}
    tracers = {}
    
    # æµ‹è¯•ä¸¤ç§æ¨¡å¼
    for mode_name, segment_mode in [("ä¼ ç»Ÿæ¨¡å¼", False), ("æ®µçº§æ¨¡å¼", True)]:
        print(f"\n{mode_name}:")
        
        tracer = ScheduleTracer(queue_manager)
        launcher = EnhancedTaskLauncher(queue_manager, tracer)
        
        # æ³¨å†Œæ‰€æœ‰ä»»åŠ¡
        for task in tasks:
            launcher.register_task(task)
        
        # æ‰§è¡Œ
        duration = 200.0
        plan = launcher.create_launch_plan(duration, "eager")
        
        executor = ScheduleExecutor(queue_manager, tracer, launcher.tasks)
        stats = executor.execute_plan(plan, duration, segment_mode=segment_mode)
        
        # åˆ†ææ‰§è¡Œæ—¶é—´çº¿
        trace_stats = tracer.get_statistics(time_window=duration)  # ä¼ å…¥æ—¶é—´çª—å£
        
        # è¯„ä¼°æ€§èƒ½
        evaluator = PerformanceEvaluator(tracer, launcher.tasks, queue_manager)
        metrics = evaluator.evaluate(duration, plan.events)
        
        # è®¡ç®—ç³»ç»Ÿåˆ©ç”¨ç‡
        system_util = calculate_system_utilization(tracer, duration)
        
        # è·å–ä¸€è‡´çš„èµ„æºåˆ©ç”¨ç‡ï¼ˆä½¿ç”¨æ—¶é—´çª—å£ï¼‰
        resource_utilization = tracer.get_resource_utilization(time_window=duration)
        
        results[mode_name] = {
            'stats': stats,
            'metrics': metrics,
            'utilization': resource_utilization,  # ä½¿ç”¨ä¸€è‡´çš„è®¡ç®—
            'system_utilization': system_util,
            'trace_stats': trace_stats,
            'evaluator': evaluator
        }
        tracers[mode_name] = tracer
        
        print(f"  å®Œæˆå®ä¾‹: {stats['completed_instances']}")
        print(f"  æ‰§è¡Œæ®µæ•°: {stats['total_segments_executed']}")
        print(f"  NPUåˆ©ç”¨ç‡: {resource_utilization.get('NPU_0', 0):.1f}%")
        print(f"  DSPåˆ©ç”¨ç‡: {resource_utilization.get('DSP_0', 0):.1f}%")
        print(f"  Systemåˆ©ç”¨ç‡: {system_util:.1f}%")
        print(f"  å¹³å‡ç­‰å¾…æ—¶é—´: {metrics.avg_wait_time:.2f}ms")
        print(f"  FPSæ»¡è¶³ç‡: {metrics.fps_satisfaction_rate:.1f}%")
    
    # æ€§èƒ½å¯¹æ¯”
    print("\næ€§èƒ½æå‡åˆ†æ:")
    for metric in ['NPU_0', 'DSP_0']:
        if metric in results['ä¼ ç»Ÿæ¨¡å¼']['utilization']:
            old_val = results['ä¼ ç»Ÿæ¨¡å¼']['utilization'][metric]
            new_val = results['æ®µçº§æ¨¡å¼']['utilization'][metric]
            improvement = ((new_val - old_val) / old_val * 100) if old_val > 0 else 0
            print(f"  {metric}åˆ©ç”¨ç‡: {improvement:+.1f}%")
    
    system_old = results['ä¼ ç»Ÿæ¨¡å¼']['system_utilization']
    system_new = results['æ®µçº§æ¨¡å¼']['system_utilization']
    system_improvement = ((system_new - system_old) / system_old * 100) if system_old > 0 else 0
    print(f"  Systemåˆ©ç”¨ç‡: {system_improvement:+.1f}%")
    
    # å…¶ä»–æŒ‡æ ‡å¯¹æ¯”
    segments_old = results['ä¼ ç»Ÿæ¨¡å¼']['stats']['completed_instances']
    segments_new = results['æ®µçº§æ¨¡å¼']['stats']['completed_instances']
    segments_improvement = ((segments_new - segments_old) / segments_old * 100) if segments_old > 0 else 0
    print(f"  å®Œæˆå®ä¾‹: {segments_improvement:+.1f}%")
    
    wait_old = results['ä¼ ç»Ÿæ¨¡å¼']['metrics'].avg_wait_time
    wait_new = results['æ®µçº§æ¨¡å¼']['metrics'].avg_wait_time
    wait_improvement = ((wait_old - wait_new) / wait_old * 100) if wait_old > 0 else 0
    print(f"  ç­‰å¾…æ—¶é—´: {wait_improvement:+.1f}% (å‡å°‘)")
    
    return results, tracers


def check_task_fps_requirements():
    """æ£€æŸ¥FPSè¦æ±‚æ»¡è¶³æƒ…å†µ"""
    print("\n\n=== FPSè¦æ±‚æ»¡è¶³æƒ…å†µåˆ†æ ===\n")
    
    # åˆ›å»ºèµ„æº
    queue_manager = ResourceQueueManager()
    queue_manager.add_resource("NPU_0", ResourceType.NPU, 40.0)
    queue_manager.add_resource("DSP_0", ResourceType.DSP, 40.0)
    
    # å‡†å¤‡ä»»åŠ¡
    tasks = prepare_tasks_with_segmentation()
    
    # æ‰“å°ä»»åŠ¡FPSè¦æ±‚
    print("ä»»åŠ¡FPSè¦æ±‚:")
    for task in tasks:  # æ˜¾ç¤ºT1-T9
        instances_needed = int(task.fps_requirement * 0.2)  # 200mså†…éœ€è¦çš„å®ä¾‹æ•°
        print(f"  {task.task_id} ({task.name}): {task.fps_requirement} FPS â†’ {instances_needed} å®ä¾‹/200ms")


def generate_visualization():
    """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
    print("\n\n=== ç”Ÿæˆå¯è§†åŒ– ===\n")
    
    # åˆ›å»ºèµ„æº
    queue_manager = ResourceQueueManager()
    queue_manager.add_resource("NPU_0", ResourceType.NPU, 40.0)
    queue_manager.add_resource("DSP_0", ResourceType.DSP, 40.0)
    
    # å‡†å¤‡ä»»åŠ¡
    tasks = prepare_tasks_with_segmentation()
    
    # å†æ¬¡è¿è¡Œæ®µçº§æ¨¡å¼ä»¥ç”Ÿæˆå¯è§†åŒ–
    tracer = ScheduleTracer(queue_manager)
    launcher = EnhancedTaskLauncher(queue_manager, tracer)
    
    # æ‰“å°ä»»åŠ¡æ³¨å†Œä¿¡æ¯
    print("ğŸ“‹ åˆ›å»ºæµ‹è¯•ä»»åŠ¡:")
    for task in tasks:
        launcher.register_task(task)  # â† å…³é”®ï¼å¿…é¡»æ³¨å†Œä»»åŠ¡
        if len(task.segments) > 1:
            print(f"  âœ“ {task.task_id} {task.name}: {len(task.segments)}æ®µæ··åˆä»»åŠ¡")
        else:
            print(f"  âœ“ {task.task_id} {task.name}: çº¯{task.segments[0].resource_type.value}ä»»åŠ¡")
    
    # æ‰§è¡Œ
    duration = 200.0
    plan = launcher.create_launch_plan(duration, "eager")
    
    print(f"\n{'='*100}")
    print("å¼€å§‹æ‰§è¡Œè°ƒåº¦ (max_time=200.0ms, mode=æ®µçº§)")
    print("="*100)
    
    executor = ScheduleExecutor(queue_manager, tracer, launcher.tasks)
    stats = executor.execute_plan(plan, duration, segment_mode=True)
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = ScheduleVisualizer(tracer)
    
    # ç”Ÿæˆæ—¶é—´çº¿å›¾
    print("\nSEGMENT æ¨¡å¼æ‰§è¡Œæ—¶é—´çº¿:\n")
    visualizer.print_gantt_chart(width=100)
    
    # ç”Ÿæˆå›¾è¡¨æ–‡ä»¶
    filename = "segmented_tasks_segment.png"
    json_filename = "segmented_tasks_segment.json"
    
    # ç”ŸæˆPNGå›¾è¡¨
    visualizer.plot_resource_timeline(filename)
    
    # ç”ŸæˆChrome Trace JSON
    visualizer.export_chrome_tracing(json_filename)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯ï¼ˆä½¿ç”¨ä¸€è‡´çš„æ—¶é—´çª—å£ï¼‰
    trace_stats = tracer.get_statistics(time_window=duration)
    resource_utilization = tracer.get_resource_utilization(time_window=duration)
    system_util = calculate_system_utilization(tracer, duration)
    
    print(f"\nç»Ÿè®¡ä¿¡æ¯:")
    print(f"  æ‰§è¡Œæ•°: {trace_stats['total_executions']}")
    print(f"  æ—¶é—´è·¨åº¦: {trace_stats['time_span']:.1f}ms")
    print(f"  èµ„æºåˆ©ç”¨ç‡: NPU={resource_utilization.get('NPU_0', 0):.1f}%, "
          f"DSP={resource_utilization.get('DSP_0', 0):.1f}%, "
          f"System={system_util:.1f}%")
    
    # éªŒè¯åˆ©ç”¨ç‡çš„é€»è¾‘ä¸€è‡´æ€§
    max_resource_util = max(resource_utilization.values()) if resource_utilization else 0
    print(f"\nåˆ©ç”¨ç‡éªŒè¯:")
    print(f"  æœ€é«˜å•èµ„æºåˆ©ç”¨ç‡: {max_resource_util:.1f}%")
    print(f"  Systemåˆ©ç”¨ç‡: {system_util:.1f}%")
    if system_util >= max_resource_util - 0.1:  # å…è®¸0.1%çš„è¯¯å·®
        print(f"  âœ“ é€»è¾‘ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡")
    else:
        print(f"  âœ— è­¦å‘Šï¼šSystemåˆ©ç”¨ç‡ä½äºæœ€é«˜èµ„æºåˆ©ç”¨ç‡ï¼")
    
    # æ£€æŸ¥ä»»åŠ¡æ‰§è¡Œæƒ…å†µ
    evaluator = PerformanceEvaluator(tracer, launcher.tasks, queue_manager)
    metrics = evaluator.evaluate(duration, plan.events)
    
    print(f"\nä»»åŠ¡æ‰§è¡Œæ¬¡æ•°:")
    for task_id in sorted(launcher.tasks.keys()):
        task = launcher.tasks[task_id]
        # ä»evaluatorçš„task_metricsä¸­è·å–å®é™…æ‰§è¡Œæƒ…å†µ
        if hasattr(evaluator, 'task_metrics') and task_id in evaluator.task_metrics:
            task_metric = evaluator.task_metrics[task_id]
            completed = task_metric.instance_count
            actual_fps = task_metric.achieved_fps
        else:
            # å¦‚æœæ²¡æœ‰task_metricsï¼Œä»completion_countè·å–
            completed = evaluator.task_completion_count.get(task_id, 0)
            actual_fps = (completed * 1000.0 / duration) if duration > 0 else 0
        
        expected = int(task.fps_requirement * duration / 1000.0)
        fps_rate = (actual_fps / task.fps_requirement * 100) if task.fps_requirement > 0 else 0
        
        status = "âœ“" if fps_rate >= 100 else "âœ—"
        print(f"  {task_id}: {completed}/{expected} "
              f"(FPSè¦æ±‚: {task.fps_requirement}) {status}")
    
    print(f"\nç”Ÿæˆæ–‡ä»¶:")
    print(f"  - {filename}")
    print(f"  - {json_filename}")


def main():
    """ä¸»å‡½æ•°"""
    print("DEMO: çœŸå®ä»»åŠ¡æ®µçº§è°ƒåº¦ä¼˜åŒ–")
    print("=" * 115)
    
    # 1. åˆ†æåˆ†æ®µç­–ç•¥
    analyze_segmented_tasks()
    
    # 1.5 åˆ†æèµ„æºéœ€æ±‚ï¼ˆæ–°å¢ï¼‰
    tasks = prepare_tasks_with_segmentation()
    print_resource_demand_analysis(tasks, bandwidth_npu=40.0, bandwidth_dsp=40.0)
    analyze_bandwidth_scenarios(tasks)
    
    # 2. åŸºå‡†æµ‹è¯•
    baseline_results, tracers = test_single_npu_dsp_baseline()
    
    # 2.5 åˆ†ææ‰§è¡Œç©ºéš™ï¼ˆæ–°å¢ï¼‰
    if 'æ®µçº§æ¨¡å¼' in tracers:
        print_execution_gap_analysis(tracers['æ®µçº§æ¨¡å¼'], window_ms=200.0)
        compare_theory_vs_actual(tasks, tracers['æ®µçº§æ¨¡å¼'], 
                               bandwidth_npu=40.0, bandwidth_dsp=40.0, window_ms=200.0)
    
    # 3. æ£€æŸ¥FPSè¦æ±‚æ»¡è¶³æƒ…å†µ
    check_task_fps_requirements()
    
    # 4. ç”Ÿæˆå¯è§†åŒ–
    generate_visualization()
    
    # æ€»ç»“
    print("\n\n" + "=" * 115)
    print("ğŸ“Š ä¼˜åŒ–æ•ˆæœæ€»ç»“")
    print("=" * 115)
    
    print("\nå…³é”®å‘ç°ï¼š")
    print("1. FORCED_SEGMENTATION ç­–ç•¥è®©T2å’ŒT3çš„NPUæ®µè¢«æœ‰æ•ˆåˆ‡åˆ†")
    print("2. æ®µçº§æ¨¡å¼å……åˆ†åˆ©ç”¨äº†åˆ†æ®µå¸¦æ¥çš„è°ƒåº¦çµæ´»æ€§")
    print("3. Systemåˆ©ç”¨ç‡å±•ç¤ºäº†æ•´ä½“ç³»ç»Ÿçš„ç¹å¿™ç¨‹åº¦")
    print("4. ä½ä¼˜å…ˆçº§ä»»åŠ¡ï¼ˆT7ã€T8ï¼‰åœ¨èµ„æºå—é™æ—¶å¯èƒ½æ— æ³•æ»¡è¶³FPSè¦æ±‚")
    
    print("\nä¼˜åŒ–å»ºè®®ï¼š")
    print("- ä½¿ç”¨å¤šèµ„æºï¼ˆå¦‚2ä¸ªNPUï¼‰æ¥æ»¡è¶³æ‰€æœ‰ä»»åŠ¡çš„FPSè¦æ±‚")
    print("- è°ƒæ•´ä»»åŠ¡ä¼˜å…ˆçº§æˆ–ä½¿ç”¨æ›´æ™ºèƒ½çš„è°ƒåº¦ç­–ç•¥")
    print("- è€ƒè™‘ä»»åŠ¡çš„æ—¶é—´ç‰¹æ€§ï¼Œä¼˜åŒ–å‘å°„æ—¶æœº")


if __name__ == "__main__":
    main()