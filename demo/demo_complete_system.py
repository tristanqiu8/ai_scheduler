#!/usr/bin/env python3
"""
å®Œæ•´ç³»ç»Ÿæ¼”ç¤º - å±•ç¤ºæ‰€æœ‰æ¨¡å—çš„ååŒå·¥ä½œ
åŒ…æ‹¬ï¼šä»»åŠ¡å‘å°„ã€æ‰§è¡Œã€è¯„ä¼°å’Œä¼˜åŒ–
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core import (
    ResourceType, TaskPriority,
    ResourceQueueManager, ScheduleTracer, 
    TaskLauncher, ScheduleExecutor,
    PerformanceEvaluator, LaunchOptimizer, OptimizationConfig
)
from viz.schedule_visualizer import ScheduleVisualizer
from scenario.real_task import create_real_tasks
import matplotlib.pyplot as plt


def demo_complete_system():
    """æ¼”ç¤ºå®Œæ•´çš„è°ƒåº¦ç³»ç»Ÿå·¥ä½œæµç¨‹"""
    print("="*80)
    print("[DEMO] AIè°ƒåº¦ç³»ç»Ÿå®Œæ•´æ¼”ç¤º")
    print("="*80)
    
    # 1. ç³»ç»Ÿåˆå§‹åŒ–
    print("\n[STEP 1] ç³»ç»Ÿåˆå§‹åŒ–")
    print("-"*40)
    
    # åˆ›å»ºèµ„æº
    queue_manager = ResourceQueueManager()
    queue_manager.add_resource("NPU_0", ResourceType.NPU, 60.0)
    queue_manager.add_resource("NPU_1", ResourceType.NPU, 60.0)
    queue_manager.add_resource("DSP_0", ResourceType.DSP, 40.0)
    queue_manager.add_resource("DSP_1", ResourceType.DSP, 40.0)
    
    print("[OK] èµ„æºé…ç½®:")
    print("  - NPU x2 (å¸¦å®½: 60.0)")
    print("  - DSP x2 (å¸¦å®½: 40.0)")
    
    # 2. åŠ è½½ä»»åŠ¡
    print("\n[STEP 2] åŠ è½½ä»»åŠ¡")
    print("-"*40)
    
    tasks = create_real_tasks()
    # é€‰æ‹©ä»£è¡¨æ€§ä»»åŠ¡
    selected_tasks = [
        tasks[0],  # T1: MOTR (CRITICAL)
        tasks[1],  # T2: YoloV8nBig (HIGH)
        tasks[2],  # T3: YoloV8nSmall (NORMAL)
        tasks[5],  # T6: reid (NORMAL)
        tasks[6],  # T7: crop (LOW)
    ]
    
    print(f"[OK] åŠ è½½äº† {len(selected_tasks)} ä¸ªä»»åŠ¡:")
    for task in selected_tasks:
        seg_info = f"{len(task.segments)}æ®µ"
        if task.segments:
            types = set(seg.resource_type.value for seg in task.segments)
            seg_info += f" ({'/'.join(types)})"
        
        print(f"  {task.task_id}: {task.name:<15} "
              f"ä¼˜å…ˆçº§={task.priority.name:<8} "
              f"FPS={task.fps_requirement:<3} "
              f"{seg_info}")
    
    # 3. åŸºçº¿æ‰§è¡Œï¼ˆæ¿€è¿›ç­–ç•¥ï¼‰
    print("\n[STEP 3] åŸºçº¿æ‰§è¡Œ (æ¿€è¿›ç­–ç•¥)")
    print("-"*40)
    
    # åˆ›å»ºè¿½è¸ªå™¨å’Œå‘å°„å™¨
    tracer_baseline = ScheduleTracer(queue_manager)
    launcher_baseline = TaskLauncher(queue_manager, tracer_baseline)
    
    # æ³¨å†Œä»»åŠ¡
    for task in selected_tasks:
        launcher_baseline.register_task(task)
    
    # åˆ›å»ºæ¿€è¿›çš„å‘å°„è®¡åˆ’
    time_window = 200.0
    plan_eager = launcher_baseline.create_launch_plan(time_window, strategy="eager")
    
    print(f"[OK] æ¿€è¿›å‘å°„è®¡åˆ’: {len(plan_eager.events)} ä¸ªå‘å°„äº‹ä»¶")
    
    # æ‰§è¡ŒåŸºçº¿
    executor_baseline = ScheduleExecutor(queue_manager, tracer_baseline, launcher_baseline.tasks)
    exec_stats_baseline = executor_baseline.execute_plan(plan_eager, time_window)
    
    print(f"[OK] æ‰§è¡Œå®Œæˆ: {exec_stats_baseline['total_segments_executed']} ä¸ªæ®µ")
    
    # è¯„ä¼°åŸºçº¿
    evaluator_baseline = PerformanceEvaluator(tracer_baseline, launcher_baseline.tasks, queue_manager)
    metrics_baseline = evaluator_baseline.evaluate(time_window, plan_eager.events)
    
    print(f"\n[BASELINE] åŸºçº¿æ€§èƒ½:")
    print(f"  ç©ºé—²æ—¶é—´: {metrics_baseline.idle_time:.1f}ms ({metrics_baseline.idle_time_ratio:.1f}%)")
    print(f"  FPSæ»¡è¶³ç‡: {metrics_baseline.fps_satisfaction_rate:.1f}%")
    print(f"  NPUåˆ©ç”¨ç‡: {metrics_baseline.avg_npu_utilization:.1f}%")
    print(f"  DSPåˆ©ç”¨ç‡: {metrics_baseline.avg_dsp_utilization:.1f}%")
    
    # 4. ä¼˜åŒ–å‘å°„ç­–ç•¥
    print("\n[STEP 4] ä¼˜åŒ–å‘å°„ç­–ç•¥")
    print("-"*40)
    
    # ä¸ºä¼˜åŒ–åˆ›å»ºç‹¬ç«‹çš„ç»„ä»¶ï¼Œä½†ä½¿ç”¨ç›¸åŒçš„èµ„æºé…ç½®
    queue_manager_opt = ResourceQueueManager()
    queue_manager_opt.add_resource("NPU_0", ResourceType.NPU, 60.0)
    queue_manager_opt.add_resource("NPU_1", ResourceType.NPU, 60.0)
    queue_manager_opt.add_resource("DSP_0", ResourceType.DSP, 40.0)
    queue_manager_opt.add_resource("DSP_1", ResourceType.DSP, 40.0)
    
    tracer_opt = ScheduleTracer(queue_manager_opt)
    launcher_opt = TaskLauncher(queue_manager_opt, tracer_opt)
    
    for task in selected_tasks:
        launcher_opt.register_task(task)
    
    # é…ç½®ä¼˜åŒ–å™¨
    opt_config = OptimizationConfig(
        idle_time_weight=0.7,        # æ›´é‡è§†ç©ºé—²æ—¶é—´
        fps_satisfaction_weight=0.2,  # ä¿è¯åŸºæœ¬FPS
        resource_balance_weight=0.1,
        fps_tolerance=0.95,          # 95%çš„FPSå®¹å¿åº¦
        max_iterations=30,           # å‡å°‘è¿­ä»£æ¬¡æ•°ä»¥åŠ å¿«æ¼”ç¤º
        population_size=20
    )
    
    optimizer = LaunchOptimizer(launcher_opt, queue_manager_opt, opt_config)
    
    print("[OK] ä¼˜åŒ–å™¨é…ç½®:")
    print(f"  ç›®æ ‡æƒé‡: ç©ºé—²æ—¶é—´={opt_config.idle_time_weight}, "
          f"FPS={opt_config.fps_satisfaction_weight}, "
          f"å‡è¡¡={opt_config.resource_balance_weight}")
    print(f"  FPSå®¹å¿åº¦: {opt_config.fps_tolerance*100}%")
    
    # è¿è¡Œä¼˜åŒ–
    best_strategy = optimizer.optimize(time_window, base_strategy="eager")
    
    # 5. æ‰§è¡Œä¼˜åŒ–åçš„ç­–ç•¥
    print("\n[STEP 5] æ‰§è¡Œä¼˜åŒ–ç­–ç•¥")
    print("-"*40)
    
    # åº”ç”¨æœ€ä¼˜ç­–ç•¥
    plan_optimized = optimizer.apply_best_strategy()
    
    if plan_optimized:
        print(f"[OK] ä¼˜åŒ–å‘å°„è®¡åˆ’: {len(plan_optimized.events)} ä¸ªå‘å°„äº‹ä»¶")
        
        # æ˜¾ç¤ºä¼˜åŒ–åçš„å‰å‡ ä¸ªäº‹ä»¶
        print("\nä¼˜åŒ–åçš„å‘å°„äº‹ä»¶ï¼ˆå‰10ä¸ªï¼‰:")
        for i, event in enumerate(plan_optimized.events[:10]):
            print(f"  {event.time:>6.1f}ms: {event.task_id}#{event.instance_id}")
        if len(plan_optimized.events) > 10:
            print(f"  ... è¿˜æœ‰ {len(plan_optimized.events)-10} ä¸ªäº‹ä»¶")
        
        # å»¶è¿Ÿç»Ÿè®¡
        delays = [e.task_id for e in plan_optimized.events 
                 if e.task_id in best_strategy.delay_factors 
                 and best_strategy.delay_factors[e.task_id] > 0]
        if delays:
            print(f"  å»¶è¿Ÿçš„ä»»åŠ¡: {len(set(delays))} ä¸ª")
        
        # æ‰§è¡Œä¼˜åŒ–è®¡åˆ’
        executor_opt = ScheduleExecutor(queue_manager_opt, tracer_opt, launcher_opt.tasks)
        exec_stats_opt = executor_opt.execute_plan(plan_optimized, time_window)
        
        print(f"[OK] æ‰§è¡Œå®Œæˆ: {exec_stats_opt['total_segments_executed']} ä¸ªæ®µ")
        
        # è¯„ä¼°ä¼˜åŒ–ç»“æœ
        evaluator_opt = PerformanceEvaluator(tracer_opt, launcher_opt.tasks, queue_manager)
        metrics_opt = evaluator_opt.evaluate(time_window, plan_optimized.events)
        
        print(f"\n[OPTIMIZED] ä¼˜åŒ–åæ€§èƒ½:")
        print(f"  ç©ºé—²æ—¶é—´: {metrics_opt.idle_time:.1f}ms ({metrics_opt.idle_time_ratio:.1f}%)")
        print(f"  FPSæ»¡è¶³ç‡: {metrics_opt.fps_satisfaction_rate:.1f}%")
        print(f"  NPUåˆ©ç”¨ç‡: {metrics_opt.avg_npu_utilization:.1f}%")
        print(f"  DSPåˆ©ç”¨ç‡: {metrics_opt.avg_dsp_utilization:.1f}%")
    
    # 6. å¯¹æ¯”åˆ†æ
    print("\n[STEP 6] æ€§èƒ½å¯¹æ¯”")
    print("-"*40)
    
    if plan_optimized and metrics_opt:
        idle_improve = metrics_opt.idle_time - metrics_baseline.idle_time
        fps_change = metrics_opt.fps_satisfaction_rate - metrics_baseline.fps_satisfaction_rate
        
        print(f"ç©ºé—²æ—¶é—´æ”¹è¿›: {idle_improve:+.1f}ms "
              f"({metrics_baseline.idle_time:.1f} â†’ {metrics_opt.idle_time:.1f})")
        print(f"FPSæ»¡è¶³ç‡å˜åŒ–: {fps_change:+.1f}% "
              f"({metrics_baseline.fps_satisfaction_rate:.1f} â†’ {metrics_opt.fps_satisfaction_rate:.1f})")
        
        if idle_improve > 0:
            print("\n[SUCCESS] ä¼˜åŒ–æˆåŠŸï¼ç©ºé—²æ—¶é—´å¢åŠ äº† {:.1f}ms".format(idle_improve))
        elif fps_change < -5:
            print("\n[WARNING] è­¦å‘Šï¼šFPSæ»¡è¶³ç‡ä¸‹é™è¶…è¿‡5%")
    
    # 7. å¯è§†åŒ–
    print("\n[STEP 7] ç”Ÿæˆå¯è§†åŒ–")
    print("-"*40)
    
    # åŸºçº¿å¯è§†åŒ–
    viz_baseline = ScheduleVisualizer(tracer_baseline)
    viz_baseline.plot_resource_timeline("demo_baseline_gantt.png")
    viz_baseline.export_chrome_tracing("demo_baseline_trace.json")
    
    # ä¼˜åŒ–åå¯è§†åŒ–
    if plan_optimized:
        viz_opt = ScheduleVisualizer(tracer_opt)
        viz_opt.plot_resource_timeline("demo_optimized_gantt.png")
        viz_opt.export_chrome_tracing("demo_optimized_trace.json")
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        evaluator_opt.export_json_report("demo_performance_report.json")
    
    print("[OK] ç”Ÿæˆçš„æ–‡ä»¶:")
    print("  - demo_baseline_gantt.png (åŸºçº¿ç”˜ç‰¹å›¾)")
    print("  - demo_baseline_trace.json (åŸºçº¿Chromeè¿½è¸ª)")
    if plan_optimized:
        print("  - demo_optimized_gantt.png (ä¼˜åŒ–åç”˜ç‰¹å›¾)")
        print("  - demo_optimized_trace.json (ä¼˜åŒ–åChromeè¿½è¸ª)")
        print("  - demo_performance_report.json (æ€§èƒ½æŠ¥å‘Š)")
    
    # 8. ä»»åŠ¡æ€§èƒ½è¯¦æƒ…
    print("\n[STEP 8] ä»»åŠ¡æ‰§è¡Œè¯¦æƒ…")
    print("-"*40)
    
    print(f"\n{'ä»»åŠ¡ID':<10} {'ä¼˜å…ˆçº§':<8} {'FPSè¦æ±‚':<8} {'åŸºçº¿FPS':<10} {'ä¼˜åŒ–FPS':<10} {'çŠ¶æ€':<6}")
    print("-"*60)
    
    for task_id in sorted(evaluator_baseline.task_metrics.keys()):
        baseline_m = evaluator_baseline.task_metrics[task_id]
        opt_m = evaluator_opt.task_metrics[task_id] if plan_optimized else None
        
        baseline_fps = f"{baseline_m.achieved_fps:.1f}"
        opt_fps = f"{opt_m.achieved_fps:.1f}" if opt_m else "N/A"
        
        status = "[OK]" if baseline_m.fps_satisfaction else "[ERROR]"
        if opt_m and opt_m.fps_satisfaction != baseline_m.fps_satisfaction:
            status = "[OK]->[ERROR]" if baseline_m.fps_satisfaction else "[ERROR]->[OK]"
        
        print(f"{task_id:<10} {baseline_m.priority.name:<8} "
              f"{baseline_m.fps_requirement:<8.1f} {baseline_fps:<10} "
              f"{opt_fps:<10} {status:<6}")
    
    # 9. æ€»ç»“
    print("\n" + "="*80)
    print("[TIP] ç³»ç»Ÿæ¼”ç¤ºæ€»ç»“")
    print("="*80)
    
    print("\nå…³é”®å‘ç°:")
    print("1. æ–°æ¶æ„æˆåŠŸåˆ†ç¦»äº†å‘å°„ã€æ‰§è¡Œå’Œè¯„ä¼°é€»è¾‘")
    print("2. æ¿€è¿›å‘å°„ç­–ç•¥æä¾›äº†åŸºçº¿æ€§èƒ½")
    print("3. ä¼˜åŒ–å™¨èƒ½å¤Ÿæ‰¾åˆ°æ›´å¥½çš„å‘å°„æ—¶æœºæ¥å¢åŠ ç©ºé—²æ—¶é—´")
    print("4. è¯„ä¼°å™¨æä¾›äº†å…¨é¢çš„æ€§èƒ½æŒ‡æ ‡")
    print("5. å¯è§†åŒ–æ”¯æŒå¤šç§æ ¼å¼ï¼ˆç”˜ç‰¹å›¾ã€Chromeè¿½è¸ªã€JSONæŠ¥å‘Šï¼‰")
    
    if plan_optimized and idle_improve > 0:
        print(f"\n[SUCCESS] ä¼˜åŒ–æˆåŠŸå°†ç©ºé—²æ—¶é—´æå‡äº† {idle_improve:.1f}ms!")
        print("   è¿™äº›é¢å¤–çš„ç©ºé—²æ—¶é—´å¯ç”¨äº:")
        print("   - ç³»ç»ŸèŠ‚èƒ½")
        print("   - å¤„ç†çªå‘ä»»åŠ¡")
        print("   - æå‡ç³»ç»Ÿå“åº”èƒ½åŠ›")


def demo_segment_visualization():
    """ä¸“é—¨æ¼”ç¤ºåˆ†æ®µæ ‡ç­¾çš„å¯è§†åŒ–"""
    print("\n\n" + "="*80)
    print("ğŸ·ï¸  åˆ†æ®µæ ‡ç­¾å¯è§†åŒ–æ¼”ç¤º")
    print("="*80)
    
    # åˆ›å»ºç®€å•åœºæ™¯
    queue_manager = ResourceQueueManager()
    queue_manager.add_resource("NPU_0", ResourceType.NPU, 60.0)
    queue_manager.add_resource("DSP_0", ResourceType.DSP, 40.0)
    
    tracer = ScheduleTracer(queue_manager)
    
    # æ‰‹åŠ¨è®°å½•ä¸€äº›åˆ†æ®µæ‰§è¡Œæ¥å±•ç¤ºæ ‡ç­¾
    print("\næ¨¡æ‹Ÿåˆ†æ®µæ‰§è¡Œ:")
    
    # ä»»åŠ¡T1çš„å¤šä¸ªåˆ†æ®µ
    segments = [
        ("T1#0_s1", "NPU_0", 0, 5),
        ("T1#0_s2", "DSP_0", 5, 10),
        ("T1#0_s3", "NPU_0", 10, 15),
        ("T1#1_seg1", "NPU_0", 20, 25),
        ("T1#1_seg2", "DSP_0", 25, 30),
        ("T1#1_seg3", "NPU_0", 30, 35),
    ]
    
    for task_id, resource, start, end in segments:
        tracer.record_execution(
            task_id, resource, float(start), float(end),
            60.0 if "NPU" in resource else 40.0,
            segment_id=task_id.split('_')[-1]
        )
        print(f"  {task_id} åœ¨ {resource} ä¸Šæ‰§è¡Œ ({start}-{end}ms)")
    
    # æ˜¾ç¤ºç”˜ç‰¹å›¾
    print("\næ–‡æœ¬ç”˜ç‰¹å›¾å±•ç¤º:")
    viz = ScheduleVisualizer(tracer)
    viz.print_gantt_chart(width=60)
    
    print("\n[OK] åˆ†æ®µæ ‡ç­¾æ ¼å¼éªŒè¯:")
    print("  - '_s1/2/3' æ ¼å¼: ç®€çŸ­æ ‡ç­¾")
    print("  - '_seg1/2/3' æ ¼å¼: å®Œæ•´æ ‡ç­¾")
    print("  ä¸¤ç§æ ¼å¼éƒ½è¢«æ”¯æŒï¼")


if __name__ == "__main__":
    # è¿è¡Œå®Œæ•´ç³»ç»Ÿæ¼”ç¤º
    demo_complete_system()
    
    # è¿è¡Œåˆ†æ®µæ ‡ç­¾æ¼”ç¤º
    demo_segment_visualization()
    
    print("\n\n[COMPLETE] æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
